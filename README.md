
## Java基础

### String类和常量池

[String不可变性](http://ddmcc.cn/2021/02/14/string/)

[String字符串长度限制](http://ddmcc.cn/2021/02/27/length-limit-on-string/)

#### String对象的两种创建方式

```java
// 先检查字符串常量池中有没有"abcd"，如果字符串常量池中没有，则创建一个，然后 str1 指向字符串常量池中的对象，如果有，则直接将 str1 指向"abcd""；
String str1 = "abcd";
// 堆中创建一个新的对象
String str2 = new String("abcd");
// 堆中创建一个新的对象
String str3 = new String("abcd");
System.out.println(str1==str2);//false
System.out.println(str2==str3);//false
```

![markdown](https://ddmcc-1255635056.file.myqcloud.com/166201f2-b832-4e59-a7d0-5aa6f0659d8b.png)


- 第一种方式是在常量池中拿对象；
- 第二种方式是直接在堆内存空间创建一个新的对象。


**String 类型的常量池比较特殊。它的主要使用方法有两种：**

- 直接使用双引号声明出来的 String 对象会直接存储在常量池中。
- 如果不是用双引号声明的 String 对象，可以使用 String 提供的 intern() 方法。String.intern() 是一个 Native 方法，它的作用是：如果运行时常量池中已经包含一个等于此 String 对象内容的字符串，则返回常量池中该字符串的引用；如果没有，JDK1.7 之前（不包含 1.7）的处理方式是在常量池中创建与此 String 内容相同的字符串，并返回常量池中创建的字符串的引用，JDK1.7 以及之后的处理方式是在常量池中记录此字符串的引用，并返回该引用

```java
String str1 = "str";
String str2 = "ing";

String str3 = "str" + "ing";//常量池中的对象
String str4 = str1 + str2; //在堆上创建的新的对象
String str5 = "string";//常量池中的对象
System.out.println(str3 == str4);//false
System.out.println(str3 == str5);//true
System.out.println(str4 == str5);//false

```

![markdown](https://ddmcc-1255635056.file.myqcloud.com/46f2e99a-54c0-47bc-9d0a-0fa627fe1a23.png)

尽量避免多个字符串拼接，因为这样会重新创建对象。如果需要改变字符串的话，可以使用 StringBuilder 或者 StringBuffer

#### newString这句话创建了几个对象？

将创建 1 或 2 个字符串。如果池中已存在字符串常量“abc”，则只会在堆空间创建一个字符串常量“abc”。如果池中没有字符串常量“abc”，那么它将首先在池中创建，然后在堆空间中创建，因此将创建总共 2 个字符串对象

**验证：**

```java
String s1 = new String("abc");// 堆内存的地址值
String s2 = "abc";
System.out.println(s1 == s2);// 输出 false,因为一个是堆内存，一个是常量池的内存，故两者是不同的。
System.out.println(s1.equals(s2));// 输出 true
```

**结果：**

```java
false
true
```

#### String、StringBuffer、StringBuilder的区别

- **可变性**

`String` 类中使用 `final` 关键字修饰字符数组来保存字符串 `private final char value[]` ，所以 `String` 对象是不可变的

>在 Java 9 之后，String 、StringBuilder 与 StringBuffer 的实现改用 `byte` 数组存储字符串 private final byte[] value

而 `StringBuilder` 与 `StringBuffer` 都继承自 `AbstractStringBuilder` 类，在 `AbstractStringBuilder` 中也是使用字符数组保存字符串 `char[]value` ，
但是没有用 `final` 关键字修饰，所以这两种对象都是可变的

- **线程安全性**

`String` 中的对象是不可变的，也就可以理解为常量，线程安全

`StringBuffer` 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的

`StringBuilder` 并没有对方法进行加同步锁，所以是非线程安全的

- **性能**

每次对 `String` 类型进行改变的时候，都会生成一个新的 `String` 对象，然后将指针指向新的 `String` 对象

`StringBuffer` 每次都会对 `StringBuffer` 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 `StringBuilder` 相比使用 `StringBuffer` 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险


#### 为什么Java9后使用byte字节数组而舍弃了char字符数组

- todo

#### 等号与equals的区别

对于基本类型来说，== 比较的是值是否相等；

对于引用类型来说，== 比较的是两个引用是否指向同一个对象地址（两者在内存中存放的地址（堆内存地址）是否指向同一个地方）；


#### hashCode与equals的相关规定


- 如果两个对象相等，则 `hashcode` 一定也是相同的

- 两个对象相等，对 `equals()` 方法返回 true

- 两个对象有相同的 `hashcode` 值，它们也不一定是相等的

综上，`equals()` 方法被覆盖过，则 `hashCode()` 方法也必须被覆盖，
**hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写 `hashCode()`，则该 `class` 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）**

### 反射

#### 为什么说反射速度慢？为什么慢？

1. 反射会进行一系列的安全性校验，并且一些方法需要通过调用 native 方法来实现

2. 如果类没被加载，还得先加载类，并经过连接等阶段，而 new 则无需查找，因为在 Linking 阶段已经将符号引用转为直接引用

3. 反射调用方法时会从方法数组中遍历查找，并且会检查可见性等操作会耗时。

4. 反射在达到一定次数时（15），会动态编写字节码并加载到内存中，这个字节码没有经过编译器优化，也不能享受JIT优化。



### 注解

#### 说说你对 Java 注解的理解

注解是通过 `@interface` 关键字来进行定义的，形式和接口差不多，只是前面多了一个@

```java
public @interface TestAnnotation {
}
```

要使注解能正常工作，还需要使用元注解，它是可以用到注解上的注解。元标签有：

- **@Retention：** 说明注解的存活时间，取值有 
  - RetentionPolicy.SOURCE 注解只在源码阶段保留，在编译器进行编译时被丢弃；
  - RetentionPolicy.CLASS  注解只保留到编译进行的时候，并不会被加载到 `JVM` 中
  - RetentionPolicy.RUNTIME 可以留到程序运行的时候，它会被加载进入到 `JVM` 中，所以在程序运行时可以获取到它们
- **@Documented：** 注解中的元素包含到 `javadoc` 中去
- **@Target：** 限定注解的应用场景
  - ElementType.FIELD 给属性进行注解；
  - ElementType.LOCAL_VARIABLE 可以给局部变量进行注解；
  - ElementType.METHOD 可以给方法进行注解；
  - ElementType.PACKAGE 可以给一个包进行注解 
  - ElementType.TYPE 可以给一个类型进行注解，如类、接口、枚举

- **@Inherited：** 若一个超类被 `@Inherited` 注解过的注解进行注解，它的子类没有被任何注解应用的话，该子类就可继承超类的注解；
- **@Repeatable：** 注解是 `Java 8` 新增加的，它允许在相同的程序元素中重复注解


#### 注解的作用

- 提供信息给编译器：编译器可利用注解来探测错误和警告信息
- 编译阶段：软件工具可以利用注解信息来生成代码、html 文档或做其它相应处理；
- 运行阶段：程序运行时可利用注解提取代码，注解是通过反射获取的，可以通过 `Class` 对象的 **isAnnotationPresent()** 方法判断它是否应用了
某个注解，再通过 **getAnnotation()** 方法获取 `Annotation` 对象


### 反射

#### 为什么说反射速度慢？为什么慢？

1. 反射会进行一系列的安全性校验，并且一些方法需要通过调用 native 方法来实现

2. 如果类没被加载，还得先加载类，并经过连接等阶段，而 new 则无需查找，因为在 Linking 阶段已经将符号引用转为直接引用

3. 反射调用方法时会从方法数组中遍历查找，并且会检查可见性等操作会耗时。

4. 反射在达到一定次数时（15），会动态编写字节码并加载到内存中，这个字节码没有经过编译器优化，也不能享受JIT优化。


### 注解





## 设计模式

#### 说说设计模式6大原则

- **单一职责原则**

`核心思想`：应该有且仅有一个原因引起类的变更

`问题描述`：假如有类Class1完成职责T1，T2，当职责T1或T2有变更需要修改时，有可能影响到该类的另外一个职责正常工作

`好处`：类的复杂度降低、可读性提高、可维护性提高、扩展性提高、降低了变更引起的风险。


- **开闭原则**

>定义：类、模块、函数等应该是可以拓展的，但是不可修改。或者说修改也不能影响到现有的功能

`核心思想`：需要变化时，应该尽量通过拓展的方式来实现变化，而不是通过修改已有代码来实现


- **里氏替换原则**

>定义：所有引用基类的地方必须能透明地使用其子类的对象


`核心思想`：在使用基类的的地方可以任意使用其子类，能保证子类完美替换基类。

`通俗来讲`：只要父类能出现的地方子类就能出现。反之，父类则未必能胜任

采用里氏替换原则的好处可以让继承的 `好处` 发挥最大的作用（如：减少创建类的工作量，提供代码重用等），
并减少继承的 `“弊”` 带来的诸多麻烦（如：继承增强了耦合性，当需要对父类的代码进行修改时，必须考虑到对子类产生的影响）。这就要求：

- 子类必须实现父类的抽象方法，但不得重写（覆盖）父类的非抽象（已实现）方法

- 子类中可以增加自己特有的方法

- 当子类覆盖或实现父类的方法时，方法的前置条件（即方法的形参）要比父类方法的输入参数更宽松

- 当子类的方法实现父类的（抽象）方法时，方法的后置条件（即方法的返回值）要比父类更严格


**简单的来说就是尽量不修改父类继承而来的方法，如果要修改也要不影响父类和其它类**


- **依赖倒置原则**

`核心思想`：高层模块不应该依赖底层模块，二者都该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象

`说明`：高层模块就是调用端，低层模块就是具体实现类。抽象就是指接口或抽象类。细节就是实现类

`通俗来讲`：依赖倒置原则的本质就是通过抽象（接口或抽象类）使个各类或模块的实现彼此独立，互不影响，实现模块间的松耦合

`问题描述`：类A直接依赖类B，假如要将类A改为依赖类C，则必须通过修改类A的代码来达成。这种场景下，类A一般是高层模块，负责复杂的业务逻辑；类B和类C是低层模块，负责基本的原子操作；假如修改类A，会给程序带来不必要的风险。

`解决方案`：将类A修改为依赖接口interface，类B和类C各自实现接口interface，类A通过接口interface间接与类B或者类C发生联系，则会大大降低修改类A的几率


- **接口隔离原则**

`核心思想`：类间的依赖关系应该建立在最小的接口上

`通俗来讲`：建立单一接口，不要建立庞大臃肿的接口，尽量细化接口，接口中的方法尽量少。也就是说，我们要为各个类建立专用的接口，而不要试图去建立一个很庞大的接口供所有依赖它的类去调用

    接口尽量小，但是要有限度 对接口进行细化可以提高程序设计灵活性，但是如果过小，则会造成接口数量过多，使设计复杂化。所以一定要适度
    
    提高内聚，减少对外交互 使接口用最少的方法去完成最多的事情
    
    为依赖接口的类定制服务 只暴露给调用的类它需要的方法，它不需要的方法则隐藏起来。只有专注地为一个模块提供定制服务，才能建立最小的依赖关系


- **迪米特原则**

`核心思想`：类间解耦

`通俗来讲`： 一个类应该对自己需要耦合或者调用的类知道越少越好。软件编程的总的原则：高内聚，低耦合

    一个处于松耦合中的类一旦被修改，则不会对关联的类造成太大的波及。
    
    在类的机构设计上， 每一个类都应当尽量降低其成员变量和成员函数的访问权限
    
    在对其他类的引用上， 一个类对其他对象的引用应当降到最低


**一句话总结：**

`单一职责原则` 告诉我们实现类要职责单一；`里氏替换原则`告诉我们不要破坏继承体系；`依赖倒置原则` 告诉我们要面向接口编程；`接口隔离原则` 告诉我们在设计接口的时候要精简单一；`迪米特法则` 告诉我们要降低耦合。而`开闭原则是总纲`，他告诉我们要对扩展开放，对修改关闭



#### 代理模式和桥接模式的异同点？


`代理`、`桥接`、`装饰器`、`适配器`，这 4 种模式是比较常用的 **结构型设计模式**。它们的代码结构非常相似。笼统来说，它们都可以称为 `Wrapper` 模式，也就是通过 `Wrapper` 类二次封装原始类。


`代理模式`：代理模式在不改变原始类接口的条件下，为原始类定义一个代理类，通过 `组合的方式` 来控制访问和增强

`桥接模式`：桥接模式的目的是将接口部分和实现部分分离，从而让它们可以较为容易、也相对独立地加以改变

`装饰器模式`：装饰者模式在不改变原始类接口的情况下，`通过继承的方式`，对原始类功能进行增强，并且支持多个装饰器的嵌套使用

`适配器模式`：适配器模式是一种事后的补救策略。适配器提供跟原始类不同的接口，而代理模式、装饰器模式提供的都是跟原始类相同的接口



#### 有几种单例的实现方式？以及它们的优缺点？

1）**饿汉式单例模式**

是最简单实现单例的方式，~~在类加载的时候就已经实现单例模式对象的生成，如果出现该单例对象占用内存很大但是从来未被调用的情况，该方式就会造成资源的浪费~~


2）**懒汉单例模式（线程不安全）**

它的优点是在第一次访问的时候才会被创建，避免了创建了没有使用而浪费资源的问题。但是每次访问都需要判断是否创建，也会影响性能。而且在 `多线程` 的情况下，它 并不是线程安全的。有可能会产生不同的对象


3）**懒汉同步式**

确保了每次只有一个线程进入方法，解决了线程安全的问题。但因为是同步方法，所以会很影响性能。而且我们只需要确保第一次访问的时候不被重复创建实例， 在第一次创建之后，同步方法就成了累赘了


4）**双重检查加锁**

这种方式是对前一种实现方式的改进，既保证了线程安全，也避免了性能影响，但是需要注意的是单例对象的引用需要用 `volatile` 关键字修饰，防止指令重排序，避免产生未初始化完全的对象


5）**静态内部类**

`优点`： 外部类加载时并不需要立即加载内部类，内部类不被加载则不去初始化instance，故而不占内存。即当SingletonPattenTest第一次被加载时， 并不需要去加载SingleTonHoler，只有当getInstance()方法第一次被调用时，才会加载SingleTonHoler类并初始化instance，这种方法不仅能确保线程安全，也能保证单例的唯一性，同时也延迟了单例的实例化。

`缺点`：

- 需要两个类去做到这一点，虽然不会创建静态内部类的对象，但是其 Class 对象还是会被创建，而且是属于方法区的对象

- 创建的单例，一旦在后期被销毁，不能重新创建


6）**注册表式**

用一个map来作为存储实例的载体，本质还是双重检查加锁的方式


7）**枚举式**

- 避免反射攻击的问题

- 避免线程安全问题。枚举类所有属性都会被声明称static类型，它是在类加载的时候初始化的，而类的加载和初始化过程都是线程安全的

- 避免序列化问题， 任何一个readObject方法，不管是显式的还是默认的，它都会返回一个新建的实例，这个新建的实例不同于该类初始化时创建的实例。枚举序列化的时候仅仅是将枚举对象的name属性输出到结果中，反序列化的时候则是通过java.lang.Enum的valueOf方法来根据名字查找枚举对象



#### 有几种动态代理的方式及它们实现的原理

动态代理主要有 **JDK 动态代理、CGLIB 动态代理**，- todo



## 集合容器

[ArrayList 源码+扩容机制分析](https://snailclimb.gitee.io/javaguide/#/docs/java/collection/ArrayList%E6%BA%90%E7%A0%81+%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90) 

[LinkedList 源码](https://snailclimb.gitee.io/javaguide/#/docs/java/collection/LinkedList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90) 

[HashMap(JDK1.8)源码+底层数据结构分析](https://snailclimb.gitee.io/javaguide/#/docs/java/collection/HashMap(JDK1.8)%E6%BA%90%E7%A0%81+%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90) 

[ConcurrentHashMap 源码+底层数据结构分析](https://snailclimb.gitee.io/javaguide/#/docs/java/collection/ConcurrentHashMap%E6%BA%90%E7%A0%81+%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90)



#### 集合框架底层数据结构总结

- **`List`**
  - ArrayList： 底层Object[]数组，线程不安全，每次扩容之后容量都会变为原来的 1.5 倍左右（oldCapacity 为偶数就是 1.5 倍，否则是 1.5 倍左右）
  - Vector：底层Object[]数组，线程不安全
  - LinkedList： 底层双向链表(JDK1.6 之前为循环链表，JDK1.7 取消了循环)

- **`Map`**
  - HashMap： JDK1.8 之前 HashMap 由`数组` + `链表` 组成的，数组是 `HashMap` 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间
  - LinkedHashMap： `LinkedHashMap` 继承自 `HashMap`，所以它的底层仍然是基于拉链式散列结构即由 **数组和链表或红黑树** 组成。另外，`LinkedHashMap` 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑
  - HashTable： 数组 + 链表组成的，数组是 HashTable 的主体，链表则是主要为了解决哈希冲突而存在的
  - TreeMap： 红黑树（自平衡的排序二叉树）

- **`Set`**
  - HashSet（无序，唯一）: 基于 `HashMap` 实现的，底层采用 `HashMap` 来保存元素
  - LinkedHashSet：LinkedHashSet 是 HashSet 的子类，并且其内部是通过 LinkedHashMap 来实现的
  - TreeSet（有序，唯一）： 红黑树(自平衡的排序二叉树)


#### 使用什么集合你是怎么选择的？

主要根据集合的特点来选用，比如我们需要根据 `键值` 获取到元素值时就选用 `Map` 接口下的集合，需要自定义排序时选择 `TreeMap`，需要按插入顺序选择 `LinkedHashMap`，不需要排序时就选择 `HashMap`，需要保证线程安全就选用 `ConcurrentHashMap`。

当我们只需要存放元素值时，就选择实现 `Collection` 接口的集合，需要保证元素唯一时选择实现 `Set` 接口的集合比如 `TreeSet` 或 `HashSet`，不需要就选择实现 `List` 接口的比如 `ArrayList` 或 `LinkedList`，然后再根据实现这些接口的集合的特点来选用


#### 为什么要使用集合？而不是数组

当我们需要保存一组 `类型相同的数据` 的时候，我们应该是用一个容器来保存，这个容器就是数组，但是，使用数组存储对象具有一定的弊端， 因为我们在实际开发中，存储的数据的类型是多种多样的，于是，就出现了“集合”，集合同样也是用来存储多个数据的。

**数组的缺点** 是一旦声明之后，长度就不可变了；同时，声明数组时的数据类型也决定了该数组存储的数据的类型；而且，数组存储的数据是 `有序的`、`可重复的`，`特点单一`。 但是集合提高了数据存储的灵活性，Java 集合不仅可以用来存储不同类型不同数量的对象，还可以保存具有映射关系的数据


### List


#### ArrayList和Vector的区别

- `ArrayList` 是 `List` 的主要实现类，底层使用 `Object[]` 存储，适用于频繁的查找工作，线程不安全 ；

- `Vector` 是 `List` 的古老实现类，底层使用 `Object[]` 存储，线程安全的。


#### ArrayList与LinkedList区别

- **是否保证线程安全：** `ArrayList` 和 `LinkedList` 都是不同步的，也就是不保证线程安全；

- **底层数据结构：**  `Arraylist` 底层使用的是 `Object` 数组；`LinkedList` 底层使用的是 双向链表 数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环。注意双向链表和双向循环链表的区别，下面有介绍到！）

- **插入和删除是否受元素位置的影响：**

`ArrayList` 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e)方法的时候， `ArrayList` 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element)）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。

`LinkedList` 采用链表存储，所以，如果是在头尾插入或者删除元素不受元素位置的影响（add(E e)、addFirst(E e)、addLast(E e)、removeFirst() 、 removeLast()），近似 O(1)，如果是要在指定位置 i 插入和删除元素的话（add(int index, E element)，remove(Object o)） 时间复杂度近似为 O(n) ，因为需要先移动到指定位置再插入。
是否支持快速随机访问： `LinkedList` 不支持高效的随机元素访问，而 `ArrayList` 支持

>快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index)方法)。

- **内存空间占用**： `ArrayList` 的空间浪费主要体现在在 `list` 列表的结尾会预留一定的容量空间，而 `LinkedList` 的空间花费则体现在它的每一个元素都需要消耗比 `ArrayList` 更多的空间（因为要存放直接后继和直接前驱以及数据）


#### RandomAccess接口的作用是什么？

源码上 `RandomAccess` 接口中什么都没有定义。所以，在我看来 `RandomAccess` 接口不过是一个标识罢了。标识什么？ 标识实现这个接口的类具有 **随机访问功能。**
并不是说 `ArrayList` 实现 `RandomAccess` 接口才具有快速随机访问功能的，
`ArrayList` 底层是数组，而 `LinkedList` 底层是链表。数组天然支持随机访问，时间复杂度为 O(1)，所以称为 **快速随机访问**。链表需要遍历到特定位置才能访问特定位置的元素，时间复杂度为 O(n)，所以不支持快速随机访问

在 binarySearch() 方法中，它要判断传入的 list 是否 `RamdomAccess` 的实例，如果是，调用 `indexedBinarySearch()` 方法，如果不是，那么调用 `iteratorBinarySearch()` 方法


#### 说一说ArrayList的扩容机制吧

**以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为 10
直到添加第 11 个元素，minCapacity(为 11)比 elementData.length（为 10）要大。进入 grow 方法进行扩容**

`ArrayList` 每次扩容之后容量都会变为原来的 1.5 倍左右（oldCapacity 为偶数就是 1.5 倍，否则是 1.5 倍左右）


```java
// minCapacity 最小容量 oldCapacity + 1
// oldCapacity >> 1  偶数为一半，奇数不到一半
int newCapacity = ArraysSupport.newLength(oldCapacity, minCapacity - oldCapacity, oldCapacity >> 1);

// minGrowth = minCapacity - oldCapacit = 1
// prefGrowth = oldCapacity >> 1
// oldLength = oldCapacity
int newLength = Math.max(minGrowth, prefGrowth) + oldLength;
```


#### 说说ensureCapacity方法的作用

`ensureCapacity(int minCapacity)` 方法在 `ArrayList` 类内部并没有被调用，所以它是提供给外部使用的。**作用：** 是扩容数组，以至少容纳 `minCapacity` 大小的元素，
**条件是：** `minCapacity` 大小大于当前数组个数并且当前数组已有元素或 `minCapacity` > `DEFAULT_CAPACITY`

**所以可以在大量增加元素之前调用 `ensureCapacity(int minCapacity)`，一次性扩容完毕，减少扩容次数。**


#### arraycopy和copyof方法

**`System.arraycopy()` 方法**

`arraycopy()` 方法是一个 `native` 方法，作用是从 **原数组中指定起始下标，复制 n 个元素到指定起始下标目标数组中**。

在 `ArrayList` 中主要用于移动数组元素和添加元素，如下图：arraycopy() 方法实现数组自己复制自己，将目标 `index` 后的元素往后移动一位，并将新的元素放到目标 `index`

![markdown](https://ddmcc-1255635056.file.myqcloud.com/d0d24a11-9423-48a7-92d9-02fce7db3fb2.png)


#### 比较HashSet、LinkedHashSet和TreeSet三者的异同

- `HashSet` 是 `Set` 接口的主要实现类 ，`HashSet` 的底层是 `HashMap`，线程不安全的，可以存储 `null` 值；

- `LinkedHashSet` 是 `HashSet` 的子类，能够按照添加的顺序遍历；

- `TreeSet` 底层使用红黑树，能够按照元素的顺序进行遍历，排序的方式有自然排序和定制排序。


#### HashSet是怎么去重的？

`HashSet` 底层是用 `HashMap` 来维护的，并将元素作为key，值则为一个固定的对象。所以当key值相同时，将不会被加入，这就是 `Set` 为社么能去重的原因。

当你把对象加入HashSet时，`HashSet` 会先计算对象的 `hashcode` 值来判断对象加入的位置，同时也会与其他加入的对象的 `hashcode` 值作比较，如果没有相符的 `hashcode`，
`HashSet` 会假设对象没有重复出现。但是如果发现有相同 `hashcode` 值的对象，这时会判断内存地址或调用 `equals()` 方法来检查对象相等的对象是否真的相同。
如果两者相同，`HashSet` 就不会让加入操作成功


### Map


#### HashMap和Hashtable的区别

- **线程是否安全：**  `HashMap` 是非线程安全的，`HashTable` 是线程安全的,因为 `HashTable` 内部的方法基本都经过 `synchronized` 修饰

- **效率：** 因为线程安全的问题，`HashMap` 要比 `HashTable` 效率高一点

- **对 Null key 和 Null value 的支持：** `HashMap` 可以存储 `null` 的 `key` 和 `value`，但 `null` 作为键只能有一个，`null` 作为值可以有多个；`HashTable` 不允许有 `null` 键和 `null` 值，否则会抛出 `NullPointerException`

- **初始容量大小和每次扩充容量大小的不同 ：** 
   - ① 创建时如果不指定容量初始值，`Hashtable` 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1。
    `HashMap` 默认的初始化大小为 `16`。之后每次扩充，容量变为原来的 2 倍。

   - ② 创建时如果给定了容量初始值，那么 `Hashtable` 会直接使用你给定的大小，而 `HashMap` 会将其扩充最接近的 2 的幂次方大小（HashMap 中的tableSizeFor()方法保证）。也就是说 `HashMap` 总是使用 2 的幂作为哈希表的大小

- **底层数据结构：** JDK1.8 以后的 `HashMap` 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。
`Hashtable` 没有这样的机制。


#### HashMap底层数据结构

-  **`JDK1.8 之前`**

**JDK1.8 之前** `HashMap` 底层是 **数组和链表** 结合在一起使用也就是 **链表散列**。`HashMap` 通过 `key` 的 `hashCode` 经过扰动函数处理过后得到 `hash` 值，
然后通过 **(n - 1) & hash** 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 `hash` 值以及 `key` 是否相同，
如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。

>**所谓 “拉链法” 就是：** 将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可
>
>
>**所谓扰动函数指的就是** `HashMap` 的 `hash` 方法。使用 `hash` 方法也就是扰动函数是为了防止一些实现比较差的 `hashCode()` 方法 换句话说使用扰动函数之后可以减少碰撞


- **`JDK1.8 之后`**

相比于之前的版本， JDK1.8 之后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间，当红黑树元素小于 6 时会转为链表

> TreeMap、TreeSet 以及 JDK1.8 之后的 HashMap 底层都用到了红黑树。红黑树就是为了解决二叉查找树的缺陷，因为二叉查找树在某些情况下会退化成一个线性结构


#### HashMap的长度为什么是2的幂次方？

- 为了减少哈希碰撞，`HashMap` 通过 `key` 的 `hashCode` 经过扰动函数处理过后得到 `hash` 值，**但是 `hash` 值太大，所以需要取余运算来得到对应的数组下标**

- 在取余操作中，如果除数 `length` 为 2 的 幂次方，那么 `hash % length` = `hash & (length - 1)` ，**采用二进制位操作 &，相对于%能够提高运算效率，这就解释了 HashMap 的长度为什么是 2 的幂次方** 


#### ConcurrentHashMap底层具体实现

- **`JDK1.7`**

一个 `ConcurrentHashMap` 里包含一个 `Segment` 数组。`Segment` 的结构和 `HashMap` 类似，是一种数组和链表结构，一个 `Segment` 包含一个 `HashEntry` 数组，
每个 `HashEntry` 是一个链表结构的元素，每个 `Segment` 守护着一个 `HashEntry` 数组里的元素，当对 `HashEntry` 数组的数据进行修改时，必须首先获得对应的 `Segment` 的锁，
`Segment` 实现了 `ReentrantLock`，所以 `Segment` 是一种可重入锁，扮演锁的角色。当一个线程占用其中一个段数据时，其他段的数据也能被其他线程访问


- **`JDK1.8`**

`ConcurrentHashMap` 取消了 `Segment` 分段锁，采用 `CAS` 和 `synchronized` 来保证并发安全。数据结构跟 `HashMap1.8` 的结构类似，**数组+链表/红黑二叉树**。
`Java 8` 在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为 O(N)）转换为红黑树（寻址时间复杂度为 O(log(N))）

`synchronized` 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发


#### ConcurrentHashMap和Hashtable的区别

- **`底层数据结构：`** 

   - `JDK1.7` 的 `ConcurrentHashMap` 底层采用 **分段的数组+链表** 实现，`JDK1.8` 采用的数据结构跟 `HashMap 1.8` 的结构一样，**数组+链表/红黑二叉树**。

   - `Hashtable` 和 `JDK1.8` 之前的 `HashMap` 的底层数据结构类似都是采用 **数组+链表** 的形式，数组是 `HashTable` 的主体，链表则是主要为了解决哈希冲突而存在的；
   
- **`实现线程安全的方式（重要）：`**

   - 在 JDK1.7 的时候，`ConcurrentHashMap`（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，
   就不会存在锁竞争，提高并发访问率；到了 JDK1.8 的时候已经摒弃了 `Segment` 的概念，而是直接用 `Node` **数组+链表/红黑树** 的数据结构来实现，并发控制使用 `synchronized` 和 `CAS` 来操作。
   （JDK1.6 以后 对 synchronized 锁做了很多优化） 整个看起来就像是优化过且线程安全的 `HashMap`，虽然在 `JDK1.8` 中还能看到 `Segment` 的数据结构，但是已经简化了属性，
   只是为了兼容旧版本；
   
   - **Hashtable(同一把锁)** :使用 `synchronized` 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 `put` 添加元素，另一个线程不能使用 `put` 添加元素，也不能使用 `get`，竞争会越来越激烈效率越低


## JVM

[Java虚拟机类加载过程](http://ddmcc.cn/2021/05/29/jvm-class-file-loading-process/)

### 类加载

#### 类的生命周期

一个类的生命周期包括加载、连接、初始化、使用、卸载5个阶段，其中连接阶段包括验证、准备、解析，具体如下：

![markdown](https://ddmcc-1255635056.file.myqcloud.com/2784440a-9233-4742-bf09-2da0d6e56250.png)


#### [类加载过程](http://ddmcc.cn/2021/05/29/jvm-class-file-loading-process/)

类加载过程包括：`加载（Loading）`、`连接（Linking）`、`初始化（Initialization）`3个阶段。其中连接过程又可以分为
验证（Verification）、准备（Preparation）、解析（Resolution）三个阶段

**加载阶段** 主要是通过类的全限定名来查找这个类的文件，将静态的类文件存储结构转化为运行时数据结构，并在内存中生成一个代表这个类的 java.lang.Class 对象，作为这个类的数据访问入口

这一步我们可以自定义类加载器去控制类文件的获取方式（重写一个类加载器的 loadClass() 方法）。数组类型不通过类加载器创建，它由 Java 虚拟机直接创建

**验证阶段** 的目的主要为了确保文件中的表示满足 静态语法或结构的约束 ，及安全性校验。主要包括文件格式验证、元数据验证、字节码验证、符号引用验证

**准备阶段** 主要为类或接口的静态字段分配内存，并将此类字段初始化为其默认值，**变量所使用的内存都将在 方法区 进行分配**。静态字段的显示初始化会在初始化阶段（Initialization）进行，而不是在准备阶段。并且准备阶段可以在加载后的任何时候进行，但必须在初始化之前完成

**解析阶段** 是虚拟机将常量池内的符号引用替换为直接引用的过程，也就是得到类或者字段、方法在内存中的指针或者偏移量

**初始化阶段** 就是执行初始化方法 `<clinit> ()` 方法的过程，是类加载的最后一步

#### 双亲委派加载机制

每一个类都有一个对应它的类加载器。系统中的 `ClassLoder` 在协同工作的时候会默认使用 `双亲委派模型` 。即在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。
加载的时候，首先会把该请求委派该父类加载器的 `loadClass()` 处理，因此所有的请求最终都应该传送到顶层的启动类加载器 `BootstrapClassLoader` 中。当父类加载器无法处理时，才由自己的 `findClass()` 方法来处理。当父类加载器为null时，会使用启动类加载器 `BootstrapClassLoader` 作为父类加载器

#### 如何实现一个自定义类加载器？

继承 `ClassLoader` 类，然后重写 `findClass` 方法

#### 如果不想用双亲委派模型怎么办？

自定义加载器的话，需要继承 `ClassLoader` 。如果我们不想打破双亲委派模型，就重写 `ClassLoader` 类中的 `findClass()` 方法即可，无法被父类加载器加载的类最终会通过这个方法被加载。
但是，如果想打破双亲委派模型则需要重写 loadClass() 方法

#### 双亲委派模型的好处？

可以避免类的重复加载（JVM 区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类），
也保证了 `Java` 的核心 API 不被篡改。如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个称为 `java.lang.Object` 类的话，那么程序运行的时候，系统就会出现多个不同的 `Object` 类

### JVM内存区域

#### 运行时数据区

**1.8之前：**

![markdown](https://ddmcc-1255635056.file.myqcloud.com/0ae211fc-8a32-4e8c-affa-9202418c4c05.png)


**1.8：**

![markdown](https://ddmcc-1255635056.file.myqcloud.com/06512b0c-a37c-4470-8940-05b256e1d1e7.png)


- **程序计数器：**

程序计数器只要有两个作用：

1. 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理
2. 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了

>程序计数器是唯一一个不会出现 OutOfMemoryError 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡


- **虚拟机栈：**

Java 虚拟机栈也是线程私有的，它的生命周期和线程相同。实际上，虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接（调用本地方法时，链接到本地方法栈的方法）、方法出口信息。

局部变量表主要存放了编译期可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）


>**Java 虚拟机栈会出现两种错误：StackOverFlowError 和 OutOfMemoryError：**
>
>`StackOverFlowError`： 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误
>
>`OutOfMemoryError`： Java 虚拟机栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常异常


- **本地方法栈：**

和虚拟机栈所发挥的作用非常相似，区别是： **虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务**

本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。
方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 `StackOverFlowError` 和 `OutOfMemoryError` 两种错误


- **堆：**

Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。**此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存**

>随着 JIT 编译期的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。
>从 JDK 1.7 开始已经默认开启逃逸分析，如果某些方法中的对象引用没有被返回或者未被外面使用（也就是未逃逸出去），那么对象可以直接在栈上分配内存

Java 堆是垃圾收集器管理的主要区域，因此也被称作GC 堆（Garbage Collected Heap）。从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，
所以 Java 堆还可以细分为：新生代和老年代：再细致一点有：Eden 空间、From Survivor、To Survivor 空间等。**进一步划分的目的是更好地回收内存，或者更快地分配内存**

在 JDK 7 版本及 JDK 7 版本之前，堆内存被通常被分为新生代、老年代和永久代。JDK 8 版本之后方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存

堆这里最容易出现的就是 OutOfMemoryError 错误，并且出现这种错误之后的表现形式还会有几种，比如：

>`OutOfMemoryError`: `GC Overhead Limit Exceeded` ： 当 JVM 花太多时间执行垃圾回收并且只能回收很少的堆空间时，就会发生此错误
>
>`java.lang.OutOfMemoryError`: `Java heap space` :假如在创建新的对象时, 堆内存中的空间不足以存放新创建的对象, 就会引发java.lang.OutOfMemoryError: Java heap space 错误

- **方法区：**

方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据


- **运行时常量池：**

运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池表（用于存放编译期生成的各种字面量和符号引用）

既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 错误

>1. JDK1.7 之前运行时常量池逻辑包含字符串常量池存放在方法区, 此时 hotspot 虚拟机对方法区的实现为永久代
>2. JDK1.7 字符串常量池被从方法区拿到了堆中, **这里没有提到运行时常量池，也就是说字符串常量池被单独拿到堆，运行时常量池剩下的东西还在方法区**， 也就是 hotspot 中的永久代
>3. JDK1.8 hotspot 移除了永久代用元空间(Metaspace)取而代之，这时候字符串常量池还在堆，运行时常量池还在方法区,，只不过方法区的实现从永久代变成了元空间(Metaspace)


#### 程序计数器为什么是私有的？

程序计数器主要有下面两个作用：

- 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。

- 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。

需要注意的是，如果执行的是 `native` 方法，那么程序计数器记录的是 `undefined` 地址，只有执行的是 `Java` 代码时程序计数器记录的才是下一条指令的地址。

**所以，程序计数器私有主要是为了线程切换后能恢复到正确的执行位置**


#### 虚拟机栈和本地方法栈为什么是私有的？

- **虚拟机栈：** 每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。

- **本地方法栈：** 和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。

**所以，为了保证线程中的局部变量不被别的线程访问到，虚拟机栈和本地方法栈是线程私有的**


#### 深拷贝与浅拷贝

- 浅拷贝

**会为被复制的对象新开辟内存，但其所有属性的值会与原对象相同**

即如果属性是基本类型，拷贝的就是基本类型的值；如果属性是引用类型（堆内存地址），拷贝的就是内存地址 ，因此如果其中一个对象改变了这个地址，就会影响到另一个对象
>对于外层对象来说是深拷贝，对象里的引用类型变量来说是浅拷贝

- 深拷贝

深拷贝会拷贝所有的属性，如果属性是引用类型，则会为其新申请一块内存，并将内存地址赋值给属性


**Object的clone方法是深拷贝还是浅拷贝？如果要实现深拷贝怎么实现？**

Object的clone方法是浅拷贝，如果要实现深拷贝可以实现 **Cloneable** 接口，并重写 `Object.clone` 方法，自己实现深克隆。或者使用序列化/反序列化的方式进行深拷贝


**ArrayList集合、HashMap、Arrays.copyOf()方法等是深拷贝还是浅拷贝？** 

对于 `ArrayList` 来说，内部是用数组实现的，ArrayList对象本身和内部的数组对象都是新的对象，但其中的元素还是引用同一个地址，所以是浅拷贝

`HashMap` 也只是浅拷贝，键和值本身都不是克隆的

`Arrays.copyOf()` 返回的数组对象是新的对象，里面的元素也还是引用同一个地址，所以也是浅拷贝


#### 堆和栈的区别？

- `物理地址`

堆的物理地址分配对对象是不连续的。在GC的时候也要考虑到不连续的分配，所以有各种算法。比如，标记-消除，复制，标记-压缩，分代（即新生代使用复制算法，老年代使用标记——压缩）

栈使用的是数据结构中的栈，先进后出的原则，物理地址分配是连续的。所以性能快。

- `内存分别`

堆因为是不连续的，所以分配的内存是在运行期确认的，因此大小不固定。一般堆大小远远大于栈

栈是连续的，所以分配的内存大小要在编译期就确认，大小是固定的

- `存放的内容`

堆存放的是对象的实例和数组。因此该区更关注的是数据的存储

栈存放：局部变量，操作数栈，返回结果。该区更关注的是程序方法的执行

- `程序的可见度`

堆对于整个应用程序都是共享、可见的。

栈只对于线程是可见的。所以也是线程私有。他的生命周期和线程相同

- `异常`

当堆栈内存满时，Java运行时抛出 `Java.lang.StackOverFlowerError`，而如果堆内存满，则抛出 `Java.lang.OutOfMemoryError`:Java堆空间错误。



#### 方法是如何调用的？

Java 栈可用类比数据结构中栈，Java 栈中保存的主要内容是 `栈帧`，每一次函数调用都会有一个对应的栈帧被压入 Java 栈，每一个函数调用结束后，都会有一个栈帧被弹出。
栈帧中保存着一些执行方法的数据，如：局部变量表、操作数栈、动态链接、返回地址等

Java 方法有两种返回方式：

- return 语句
- 抛出异常

不管哪种返回方式都会导致栈帧被弹出


#### 方法区和永久代的关系

方法区是 Java 虚拟机规范中的定义，是一种规范，永久代是 HotSpot 的概念，是 HotSpot 对方法区的实现。，一个是标准一个是实现，其他的虚拟机实现并没有永久代这一说法


#### 为什么要将永久代替换为元空间呢？

1. 整个永久代有一个 JVM 本身设置的固定大小上限，无法进行调整，而元空间使用的是直接内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小

>当元空间溢出时会得到如下错误： `java.lang.OutOfMemoryError: MetaSpace` 
>
>`-XX：MaxMetaspaceSize` 标志设置最大元空间大小，默认值为 unlimited，这意味着它只受系统内存的限制

2. 元空间里面存放的是类的元数据，这样加载多少类的元数据就不由 MaxPermSize 控制了, 而由系统的实际可用空间来控制，这样能加载的类就更多了

### 内存分配与垃圾回收

#### 对象内存分配机制

![markdown](https://ddmcc-1255635056.file.myqcloud.com/95d86b44-95d5-453c-917d-61106f3a5a67.png)

- `对象优先在 eden 区分配`

目前主流的垃圾收集器都会采用分代回收算法，因此需要将堆内存分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。针对新生代存活时间短对象

**大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s0 或者 s1（分配到当时的FROM 区），
并且对象的年龄还会加 1(Eden 区->Survivor 区后对象的初始年龄变为 1)，当它的年龄达到15或达到动态晋升年龄阈值，就会被晋升到老年代中**


>"From"和"To"会交换他们的角色，也就是新的"To"就是上次 GC 前的“From”，新的"From"就是上次 GC 前的"To"。不管怎样，都会保证名为 To 的 Survivor 区域是空的。Minor GC 会一直重复这样的过程，直到“To”区被填满，"To"区被填满之后，会将所有对象移动到老年代中

- `大对象直接进入老年代`

大对象就是需要大量连续内存空间的对象（比如：字符串、数组）

**为什么要这样呢？**

为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率


- `长期存活的对象将进入老年代`

既然采用分代回收算法，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这一点，虚拟机给每个对象一个对象年龄（Age）计数器

对象在 Survivor 中每熬过一次 MinorGC，年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 可以通过参数 -XX:MaxTenuringThreshold 来设置 ）或者达到 `动态晋升年龄阀值`，就会被晋升到老年代中。


#### 动态计算晋升年龄阈值

遍历所有 `Survivor` 区域对象，按照 **年龄段从小到大对其所占用的大小进行累积** ，当加入某个年龄段后，累加的占用大小超过默认的 `-XX:TargetSurvivorRatio`（50%）时，取这个年龄和 `-XX:MaxTenuringThreshold` (15)中更小的一个值，作为新的晋升年龄阈值

```java
uint ageTable::compute_tenuring_threshold(size_t survivor_capacity) {
  // survivor_capacity是survivor空间的内存大小
  // TargetSurvivorRatio survivor空间存活大小比例
  // desired_survivor_size 根据比例计算出期望存活对象内存总大小
  size_t desired_survivor_size = (size_t)((((double) survivor_capacity)*TargetSurvivorRatio)/100);
  size_t total = 0;
  uint age = 1;
  while (age < table_size) {
    // sizes数组是每个年龄段对象大小，根据年龄取出整个年龄段所占用的内存大小
    total += sizes[age];
    // 直到累计总内存大于期望的占用大小
    if (total > desired_survivor_size) break;
    age++;
  }
  // 用当前age和MaxTenuringThreshold 对比找出最小值作为结果
  uint result = age < MaxTenuringThreshold ? age : MaxTenuringThreshold;
    ...
}
```

#### 为什么设置新生代的年龄不能超过15？


在 `hotspots` 实现中，对象头的 `markword` 用了 `4bit` 去表示分代年龄，那么能表示的最大范围就是0-15（1111）。所以这也就是为什么设置新生代的年龄不能超过15，工作中可以通过 `-XX:MaxTenuringThreshold` 去调整，但是一般我们不会动


#### 垃圾回收算法

**标记-清除算法**

标记-清除分为“标记”和“清除”阶段：**首先标记出所有不需要回收的对象**，在标记完成后统一回收掉所有没有被标记的对象。它是最基础的收集算法，后续的算法都是对其不足进行改进得到。

这种垃圾收集算法会带来两个明显的问题：

- `效率问题`
- `空间问题（标记清除后会产生大量不连续的碎片）`


**标记-复制算法**

为了解决效率问题，“标记-复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收


**标记-整理算法**

根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内


**分代收集算法**

当前虚拟机的垃圾收集都采用分代收集算法，只是根据对象存活周期的不同将内存分为几块。一般将 java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。

**比如在新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集**



#### 为什么堆内存要分为新生代、老年代？

其实不分代完全可以，分代的好处就是优化GC性能。如果没有分代，所有的对象都在一块，这样就会对堆的所有区域进行扫描。而我们的很多对象都是朝生夕死的，如果分代的话，我们把新创建的对象放到某一地方，当GC的时候先把这块存“朝生夕死”对象的区域进行回收，这样就会腾出很大的空间出来

**所以这样进一步划分的目的是更好地回收内存，或者更快地分配内存**


#### 为什么要有Survivor区？

预筛选避免每进行一次 `Minor GC`，存活的对象就被送到老年代

Survivor的存在意义，就是减少被送到老年代的对象，进而减少Full GC的发生，`Survivor` 的预筛选保证，只有经历一定次数 `Minor GC` 还能在新生代中存活的对象，才会被送到老年代

但是你可能会说不放`Survivor`，每次gc再判断对象的年龄行不行？这样的话每次都要扫描整个新生代，gc消耗的时间变长

**为什么要设置两个Survivor区**

设置两个Survivor区最大的好处就是解决了碎片化。新生代一般采用 `标记-复制` 的回收算法。但是复制算法必须要有另一块内存作为存放对象，来避免碎片化的发生


#### 新生代gc工作流程

![markdown](https://ddmcc-1255635056.file.myqcloud.com/9e289f4e-7e61-49bc-97a6-9d5ac4d0be6f.png)


HotSpot JVM把年轻代分为了三部分：`1个Eden区`和`2个Survivor区`（分别叫from和to）。默认比例为8（Eden）：1（一个survivor）

一般情况下，新创建的对象都会被分配到Eden区(一些大对象特殊处理)，这些对象经过第一次Minor GC后，如果仍然存活，将会被移到Survivor区。对象在Survivor区中每熬过一次Minor GC，年龄就会增加1岁，当它的年龄增加到一定程度时，就会被移动到年老代中。

因为年轻代中的对象基本都是朝生夕死的(80%以上)，所以在年轻代的垃圾回收算法使用的是复制算法，复制算法的基本思想就是将内存分为两块，每次只用其中一块，当这一块内存用完，就将还活着的对象复制到另外一块上面。复制算法不会产生内存碎片

**在GC开始的时候，对象只会存在于Eden区和名为“From”的Survivor区，Survivor区“To”是空的。紧接着进行GC，Eden区中所有存活的对象都会被复制到“To”，而在“From”区中，仍存活的对象会根据他们的年龄值来决定去向。年龄达到一定值(年龄阈值，可以通过-XX:MaxTenuringThreshold来设置)的对象会被移动到年老代中，没有达到阈值的对象会被复制到“To”区域。经过这次GC后，Eden区和From区已经被清空。这个时候，“From”和“To”会交换他们的角色，也就是新的“To”就是上次GC前的“From”，新的“From”就是上次GC前的“To”。不管怎样，都会保证名为To的Survivor区域是空的。Minor GC会一直重复这样的过程，直到“To”区被填满，“To”区被填满之后，会将所有对象移动到年老代中**


#### 如何判断对象是否死亡（两种方法）

- 引用计数法：

给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1；任何时候计数器为 0 的对象就是不可能再被使用的
    这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题
- 可达性分析算法：

基本思想就是通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的


>可作为 GC Roots 的对象包括下面几种:
>
>虚拟机栈(栈帧中的本地变量表)中引用的对象
>
>本地方法栈(Native 方法)中引用的对象
>
>方法区中类静态属性引用的对象
>
>方法区中常量引用的对象
>
>所有被同步锁持有的对象



#### MinorGc和FullGC有什么不同呢？

Partial GC：并不收集整个GC堆的模式

- Young GC：只收集young gen的GC
- Old GC：只收集old gen的GC。只有CMS的concurrent collection是这个模式
- Mixed GC：收集整个young gen以及部分old gen的GC。只有G1有这个模式

Full GC：收集整个堆，包括young gen、old gen、perm gen（如果存在的话）等所有部分的模式。


#### 什么是空间分配担保机制？

在发生 `Minor GC` 之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么 `Minor GC` 可以确保是安全的。
如果不成立，则虚拟机会查看 `HandlePromotionFailure` 设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 `Minor GC`，尽管这次 `Minor GC` 是有风险的；如果小于，或者 `HandlePromotionFailure`设置不允许冒险，那这时也要改为进行一次 `Full GC` 。

>上面说的风险是什么呢？我们知道，新生代使用复制收集算法，但为了内存利用率，只使用其中一个Survivor空间来作为轮换备份，因此当出现大量对象在Minor GC后仍然存活的情况（最极端的情况就是内存回收后新生代中所有对象都存活），就需要老年代进行分配担保，把Survivor无法容纳的对象直接进入老年代

### Java对象


#### 对象的创建过程

![markdown](https://ddmcc-1255635056.file.myqcloud.com/629b9d68-355f-400b-8717-b3b47a12a0ae.png)

**Step1:类加载检查**

虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程


**Step2:分配内存**

在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来


**Step3:初始化零值**

内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值


**Step4:设置对象头**

初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄、锁等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式


**Step5:执行 init 方法**

在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，<init> 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 <init> 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来



#### 对象内存的分配方式？

分配方式有 `指针碰撞` 和 `空闲列表` 两种

选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是"标记-清除"，还是"标记-整理"（也称作"标记-压缩"），值得注意的是，复制算法内存也是规整的

![markdown](https://ddmcc-1255635056.file.myqcloud.com/a209c95b-510b-432f-aabf-e2740d9dd7ee.png)


**内存分配并发问题**

在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全：

- **CAS+失败重试：** CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。
- **TLAB：** 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配


#### 对象的内存布局

在 Hotspot 虚拟机中，对象在内存中的布局可以分为 3 块区域：`对象头`、`实例数据`和`对齐填充`

**对象头** 包括两部分信息：

- 第一部分(mark word 8字节)用于存储对象自身的运行时数据（哈希码、GC 分代年龄、锁状态标志等等）

- 另一部分是类型指针（class pointer 8字节），即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是那个类的实例

- length：**数组对象持有** 大小占用4字节

**实例数据** 部分是对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容，包含所有成员变量

>boolean和byte：1字节
>
>short和char：2字节
>
>int和float：4字节
>
>long和double：8字节 
>
>reference：8字节

**对齐填充部分** 仅仅起占位作用。 因为 Hotspot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，
换句话说就是对象的大小必须是 8 字节的整数倍。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全


#### 对象的访问定位

对象的访问方式由虚拟机实现而定，目前主流的访问方式有 `使用句柄` 和 `直接指针` 两种：

1. **句柄：** 如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息

![markdown](https://ddmcc-1255635056.file.myqcloud.com/6cc845e2-3e56-4108-88f1-4b956ea68217.png)

2. **直接指针：** 如果使用直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而 reference 中存储的直接就是对象的地址

![markdown](https://ddmcc-1255635056.file.myqcloud.com/03175ed3-cf2a-4aa6-81f7-637cbdf6ec33.png)


**这两种对象访问方式各有优势。使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。
使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销**


#### Java中有哪些引用类型？

`强引用：` 发生 gc 的时候不会被回收

`软引用：` 有用但不是必须的对象，在发生内存溢出之前会被回收

`弱引用：` 有用但不是必须的对象，在下一次GC时会被回收

`虚引用（幽灵引用/幻影引用）：` 无法通过虚引用获得对象，用 PhantomReference 实现虚引用，虚引用的用途是在 gc 时返回一个通知

### 垃圾回收器

- **`串行（Serial）回收器是单线程的一个回收器，简单、易实现、效率高`**

![markdown](https://ddmcc-1255635056.file.myqcloud.com/2c00d3c5-88f7-444c-802a-8d44eb049453.png)

它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ "Stop The World" ），直到它收集结束

**新生代采用标记-复制算法，老年代采用标记-整理算法**

- **`并行（ParNew）回收器是Serial的多线程版，可以充分的利用CPU资源，减少回收的时间`**

![markdown](https://ddmcc-1255635056.file.myqcloud.com/914abf09-dd8d-4e59-8637-189025c5e73b.png)

除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样

**新生代采用标记-复制算法，老年代采用标记-整理算法**

- **`吞吐量优先（Parallel Scavenge）回收器，侧重于吞吐量的控制，JDK 1.8 默认使用的是 Parallel Scavenge + Parallel Old`**

![markdown](https://ddmcc-1255635056.file.myqcloud.com/31ad7c3f-a04b-4f58-8fec-6a8613337779.png)


**新生代采用标记-复制算法，老年代采用标记-整理算法**

- **`并发标记清除（CMS，Concurrent Mark Sweep）回收器是一种以获取最短回收停顿时间为目标的回收器，该回收器是基于“标记-清除”算法实现的`**

![markdown](https://ddmcc-1255635056.file.myqcloud.com/a2cd0a8d-aba1-4d98-9276-2f3acd59b69c.png)

它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤：

- 初始标记： 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ；
- 并发标记： 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。
- 重新标记： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短
- 并发清除： 开启用户线程，同时 GC 线程开始对未标记的区域做清扫。


主要优点：**并发收集**、**低停顿**。但是它有下面三个明显的缺点：

- 对 CPU 资源敏感；
- 无法处理浮动垃圾；
- 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生


- **`G1 收集器`**

被视为 JDK1.7 中 HotSpot 虚拟机的一个重要进化特征。它具备一下特点：

- **并行与并发**：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。
- **分代收集**：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。
- **空间整合**：与 CMS 的“标记-清理”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。
- **可预测的停顿**：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。

G1 收集器的运作大致分为以下几个步骤：

- **初始标记**
- **并发标记**
- **最终标记**
- **筛选回收**

G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来) 。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零


## 网络协议

### TCP

#### TCP是什么？

`面向连接`，`可靠的传输协议`

#### TCP三次握手协议

- 客户端–发送带有 SYN 标志的数据包–一次握手–服务端
- 服务端–发送带有 SYN/ACK（syn + 1） 标志的数据包–二次握手–客户端
- 客户端–发送带有带有 ACK（syn + 1） 标志的数据包–三次握手–服务端


#### 为什么要三次握手？

三次握手的目的是建立可靠的通信信道，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的

第一次SYN+ACK保证客户端到服务端发送接收数据是正常的。服务端发送SYN是为了保证服务端到客户端发送数据也是正常的


#### 第2次握手传回了ACK，为什么还要传回SYN？

接收端传回发送端所发送的ACK是为了告诉客户端，我接收到的信息确实就是你所发送的信号了，这表明从客户端到服务端的通信是正常的。而回传SYN则是为了建立并确认从服务端到客户端的通信


#### 四次挥手协议

- 客户端-发送一个 FIN，用来关闭客户端到服务器的数据传送
- 服务器-收到这个 FIN，它发回一 个 ACK，确认序号为收到的序号加1 。和 SYN 一样，一个 FIN 将占用一个序号
- 服务器-关闭与客户端的连接，发送一个FIN给客户端
- 客户端-发回 ACK 报文确认，并将确认序号设置为收到序号加1


#### 为什么要四次挥手？

任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接

举个例子：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束


#### HTTP长连接，短连接

在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话

而从HTTP/1.1起，默认使用长连接，用以保持连接特性，使用长连接的HTTP协议，会在响应头加入这行代码：`Connection:keep-alive`
在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接

**HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接**


#### HTTP1.0和HTTP1.1的主要区别是什么?

长连接 : 在HTTP/1.0中，默认使用的是短连接，HTTP/1.1的持续连接有非流水线方式和流水线方式流水线方式是客户在收到HTTP的响应报文之前就能接着发送新的请求报文。与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求

**错误状态响应码 :** 在HTTP1.1中新增了24个错误状态响应码

**带宽优化及网络连接的使用：** HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206

#### HTTP和HTTPS的区别？

**端口** ：HTTP的URL由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认使用端口443。

**安全性和资源消耗：** HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS是运行在SSL/TLS之上的HTTP协议，SSL/TLS 运行在TCP之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源


## 浏览器

#### Http无状态链接，如何实现session跟踪？

大部分情况下，我们都是通过在 Cookie 中附加一个 Session ID 来方式来跟踪

- Cookie 被禁用怎么办?
- 最常用的就是利用 URL 重写把 Session ID 直接附加在URL路径的后面

#### Cookie和Session的区别

- **存储位置：** Cookie 存储在客户端中，而Session存储在服务器上
- **安全性：** 相对来说 Session 安全性更高。如果要在 Cookie 中存储一些敏感信息，不要直接写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解
- **作用：** Cookie 一般用来保存用户信息比如 token，Session 的主要作用就是通过服务端记录用户的状态

#### 在浏览器中输入url地址->>显示主页的过程

1. DNS解析：获取域名对应IP
2. TCP连接：三次握手
3. 发送HTTP请求
4. 服务器处理请求并返回HTTP报文
5. 浏览器解析渲染页面
6. 连接结束


## 并发编程

#### 什么是线程和进程？

- 进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。在 Java 中，
当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程

- 线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的堆和方法区资源，
但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程


#### 线程有几种创建方式？

创建线程有三种方式： **继承Thread** 、 **实现Runnable接口** 、 **实现Callable接口结合Future**


- **继承Thread，重写 run 方法**

```java
class MyThread extends Thread {
    
    @Override
    public void run() {
  
    }
    
}
```

- **实现Runnable接口，重写 run 方法**

```java
class MyRunable implements Runnable {
    
    @Override
    public void run() {
        
    }
}
```


- 实现Callable接口结合FutureTask


创建一个实现了 Callable<T> 接口的类，并实现 `call` 方法

```java
class MyFutureTask implements Callable<String> {
    
    @Override
    public String call() throws Exception {
   
    }
}
```

通过 `Callable` 实例创建 `FutureTask` ，然后通过 `FutureTask` 实例创建并启动线程


```java
public static void main(String[]args) {
    // 创建异步任务
    FutureTask<String> futureTask = new FutureTask<>(new MyFutureTask());
    // 启动线程
    new Thread(futureTask).start();
    String result = futureTask.get();
```


#### 说说线程的生命周期和状态？

线程创建之后处于 **NEW 新建状态** ，调用 `start()` 方法后开始运行，线程这时候处于 **READY 就绪状态**。就绪状态的线程获得了 `CPU` 时间片（timeslice）后就处于 **RUNNING 运行状态**。
在执行过程中，当线程执行 `wait()` 方法之后，线程进入 **WAITING 等待状态**。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而 **TIME_WAITING 超时等待状态** 相当于在等待状态的基础上增加了超时限制，比如通过 `sleep(long millis)` 方法或 `wait(long millis)`方法可以将 `Java` 线程置于 `TIME_WAITING` 状态。
当超时时间到达后 `Java` 线程将会返回到 **READY 就绪状态**。当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到 **BLOCKED（阻塞） 状态**。线程在执行 `Runnable` 的 `run()` 方法之后将会进入到 **TERMINATED 终止状态**


#### 说说sleep方法和wai方法区别和共同点？

- 两者最主要的区别在于：**sleep() 方法没有释放锁，而 wait() 方法释放了锁** 。

- 两者都可以暂停线程的执行。

- wait() 通常被用于线程间交互/通信，sleep() 通常被用于暂停执行。

- wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout) 超时后线程会自动苏醒


#### 为什么我们不能直接调用run方法？


new 一个 Thread，线程进入了新建状态。调用 `start()` 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 `start()` 会执行线程的相应准备工作，然后自动执行 `run()` 方法的内容，这是真正的多线程工作。 
但是，直接执行 `run()` 方法，会把 run() 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。

**总结： 调用 start() 方法方可启动线程并使线程进入就绪状态，直接执行 run() 方法的话不会以多线程的方式执行。**

#### 为什么要使用多线程呢？

先从总体上来说：

- **从计算机底层来说：** 线程可以比作是轻量级的进程，是程序执行的最小单位,线程间的切换和调度的成本远远小于进程。另外，多核 CPU 时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。

- **从当代互联网发展趋势来说：** 现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。


**再深入到计算机底层来探讨：**

- **单核时代：** 在单核时代多线程主要是为了提高 CPU 和 IO 设备的综合利用率。举个例子：当只有一个线程的时候会导致 CPU 计算时，IO 设备空闲；进行 IO 操作时，CPU 空闲。我们可以简单地说这两者的利用率目前都是 50%左右。但是当有两个线程的时候就不一样了，当一个线程执行 CPU 计算时，另外一个线程可以进行 IO 操作，这样两个的利用率就可以在理想情况下达到 100%了。

- **多核时代:** 多核时代多线程主要是为了提高 CPU 利用率。举个例子：假如我们要计算一个复杂的任务，我们只用一个线程的话，CPU 只会一个 CPU 核心被利用到，而创建多个线程就可以让多个 CPU 核心被利用到，这样就提高了 CPU 的利用率


#### 使用多线程可能带来什么问题？

并发编程的目的就是为了能提高程序的执行效率、提高程序运行速度，但是并发编程并不总是能提高程序运行速度的，而且并发编程可能会遇到很多问题，比如：内存泄漏、死锁、线程不安全等等


#### 什么是线程死锁？如何避免死锁？

>什么是死锁：多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止

**死锁必须具备以下四个条件：**

- **互斥条件：** 该资源任意一个时刻只由一个线程占用。

- **请求与保持条件：** 一个进程因请求资源而阻塞时，对已获得的资源保持不放。

- **不可剥夺条件:** 线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。

- **循环等待条件:** 若干进程之间形成一种头尾相接的循环等待资源关系


**如何预防死锁？** 破坏死锁的产生的必要条件即可：

- `坏请求与保持条件：` 一次性申请所有的资源。

- `破坏不剥夺条件：` 占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。

- `破坏循环等待条件：` 靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。


#### 说说并发与并行的区别？

- **并发：** 同一时间段，多个任务都在执行 (单位时间内不一定同时执行)

- **并行：** 单位时间内，多个任务同时执行


#### 什么是上下文切换？

多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。

概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。**任务从保存到再加载的过程就是一次上下文切换**


#### 并发编程三大特性


- **原子性** : 一个的操作或者多次操作，要么所有的操作全部都得到执行并且不会收到任何因素的干扰而中断，要么所有的操作都执行，要么都不执行。synchronized 可以保证代码片段的原子性。

- **可见性** ：当一个变量对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。volatile 关键字可以保证共享变量的可见性。

- **有序性** ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。volatile 关键字可以禁止指令进行重排序优化。


### 线程池

#### 为什么要用线程池？

**使用线程池的好处：**

- **降低资源消耗：** 通过重复利用已创建的线程降低线程创建和销毁造成的消耗。

- **提高响应速度：** 当任务到达时，任务可以不需要的等到线程创建就能立即执行

- **提高线程的可管理性：** 线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控


#### 线程池ThreadPoolExecutor重要参数

![markdown](https://ddmcc-1255635056.file.myqcloud.com/e23a8ac8-16f7-4715-8c62-3638898e6cb2.png)


**ThreadPoolExecutor 3 个最重要的参数：**

 - **`corePoolSize`** : 核心线程数线程数定义了最小可以同时运行的线程数量。

- **`maximumPoolSize`** : 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。

- **`workQueue`**: 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

**ThreadPoolExecutor其他常见参数:**

 - `keepAliveTime:` 当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁；

 - `unit` : `keepAliveTime` 参数的时间单位

- `threadFactory` : `executor` 创建新线程的时候会用到

- `handler`: 拒绝策略


#### 线程池threadFactory用来做什么？

线程创建的工厂，新的线程都是由 `ThreadFactory` 创建的，自定义 `ThreadFactory` 线程创建工厂可以自定义线程的创建，如修改线程组、名、优先级等


#### jdk都有哪些线程池？你是怎么选择的？

`Executors` 类封装了4个创建线程池的工厂方法。内部还是通过调用 `ThreadPoolExecutor` 构造函数来创建的：

- **FixedThreadPool**：该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务

- **SingleThreadExecutor**：方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务

- **CachedThreadPool**：该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用

- **ScheduledThreadPool**：创建一个定长线程池，支持定时及周期性任务执行

**关于线程池的选择：**

《阿里巴巴 Java 开发手册》中 **强制线程池不允许使用 `Executors` 去创建**，而是通过 `ThreadPoolExecutor` 的方式，这样的处理方式规避资源耗尽的风险

>Executors 返回线程池对象的弊端如下：
>
>FixedThreadPool 和 SingleThreadExecutor (使用无界队列)： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致 OOM
>
>CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致 OOM


**所以一般推荐通过 `ThreadPoolExecutor` 构造的方式自己来创建**


#### 介绍一下线程池可选择的队列

- `ArrayBlockingQueue`：有界阻塞队列，基于数组的先进先出（FIFO），其构造必须指定大小。其并发控制采用 `ReentrantLock` 来控制，不管是插入操作还是读取操作，都需要获取到锁才能进行操作。当队列容量满时，尝试将元素放入队列将导致操作阻塞;尝试从一个空队列中取一个元素也会同样阻塞。**默认情况下不能保证线程访问队列的公平性**


- `LinkedBlockingQueue`：底层基于单向链表实现的阻塞队列，可以当做无界队列也可以当做有界队列来使用，同样满足 FIFO 的特性，与 `ArrayBlockingQueue` 相比起来具有更高的吞吐量，为了防止 `LinkedBlockingQueue` 容量迅速增，损耗大量内存。通常在创建 `LinkedBlockingQueue` 对象时，会指定其大小，如果未指定，容量等于 `Integer.MAX_VALUE`

- `SynchronizedQueue`：

- `PriorityBlockingQueue`：是一个支持优先级的无界阻塞队列。默认情况下元素采用自然顺序进行排序，也可以通过自定义类实现 `compareTo()` 方法来指定元素排序规则，或者初始化时通过构造器参数 `Comparator` 来指定排序规则。并发控制采用的是 `ReentrantLock`，队列为无界队列，内部是使用平衡二叉树实现的，遍历不保证有序


#### 说说线程池拒绝策略，怎么自定义拒绝策略？

**内置四种拒绝策略：**

- CallerRunsPolicy （用主线程执行）

- AbortPolicy (**`默认`**)（抛弃任务并抛出异常）

- DiscardOldestPolicy （抛弃等待队列第一个任务，将当前任务加入）

- DiscardPolicy （放弃任务并且什么都不做）


**自定义拒绝策略**

实现 `RejectedExecutionHandler` 类，实现 `rejectedExecution()` 方法，并设置线程池的拒绝策略为自定义的策略 （策略模式）


#### 线程池被创建后里面有线程吗？

**线程池被创建后如果没有任务过来，里面是不会有线程的**。如果需要预热的话可以调用下面的两个方法：

- preStartCoreThread()：创建一个线程

- preStartAllCoreThread()：创建所有线程


#### 核心线程数会被回收吗？需要什么设置？

**核心线程数默认是不会被回收的** ，如果需要回收核心线程数，可以调用 `allowCoreThreadTimeOut(true)， 该值默认为 false`


### AQS

[Java并发之AQS详解](https://www.cnblogs.com/waterystone/p/4920797.html)

[Java并发包基石-AQS详解](https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html)


#### 请你说一下自己对于AQS原理的理解？

**`AQS` 核心思想是，如果被请求的共享资源未被占用，则将当前请求的线程设置为占用的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 `AQS` 是用 `CLH` 队列锁实现的，即将暂时获取不到锁的线程加入到队列中**

>CLH(Craig,Landin and Hagersten)队列（`FIFO`）是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。`AQS` 是将每条请求共享资源的线程封装成一个队列的结点（Node）来实现锁的分配

`AQS` 使用一个 `int` 成员变量来表示同步状态，通过内置的 `FIFO` 队列来完成获取资源线程的排队工作。`AQS` 使用 `CAS` 对该同步状态进行原子操作实现对其值的修改


#### AQS对资源的共享方式

**`AQS` 定义两种资源共享方式**

- `Exclusive（独占）`：只有一个线程能执行，如 `ReentrantLock`。又可分为公平锁和非公平锁：

- `Share（共享）`：多个线程可同时执行，如 `CountDownLatch`、`Semaphore`、 `CyclicBarrier`、`ReadWriteLock`

`ReentrantReadWriteLock` 可以看成是组合式，因为 `ReentrantReadWriteLock` 也就是读写锁允许多个线程同时对某一资源进行读

不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 `state` 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），`AQS` 已经在顶层实现好了


#### AQS相关组件介绍

- **`ReentrantLock`（可重入锁）**

`ReentrantLock` 的 `state` 初始化为 0，表示未锁定状态。A 线程 `lock()` 时，会调用 `tryAcquire()` 独占该锁并将 `state + 1`（CAS实现）。此后，
其他线程再 `tryAcquire()` 时就会失败（失败后等待/重试由AQS维护），直到 `A` 线程 `unlock()` 到 `state = 0`（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A 线程自己是可以重复获取此锁的（state 会累加），这就是 **可重入的概念**。但要注意，获取多少次就要释放多么次，这样才能保证 `state` 是能回到0


- **`CountDownLatch`（倒计时器）**


`CountDownLatch` 任务分为 `N` 个子线程去执行，`state` 也初始化为 `N`（注意 `N` 要与线程个数一致）。这 `N` 个子线程是并行执行的，每个子线程执行完后 `countDown()` 一次，`state` 会CAS(Compare and Swap)减 `1`。等到所有子线程都执行完后(即 `state = 0` )，会 `unpark()` 主调用线程，然后主调用线程就会从 `await()` 函数返回，继续后余动作


- **`CyclicBarrier`（循环栅栏）**

`CyclicBarrier` 和 `CountDownLatch` 非常类似，它也可以实现线程间的技术等待，但是它的功能比 `CountDownLatch` 更加复杂和强大。主要应用场景和 `CountDownLatch` 类似。
`CyclicBarrier` 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。`CyclicBarrier` 默认的构造方法是 `CyclicBarrier(int parties)`，其参数表示屏障拦截的线程数量，每个线程调用 `await()` 方法告诉 `CyclicBarrier` 我已经到达了屏障，然后当前线程被阻塞


### CAS和Atomic原子类


#### 了解CAS吗

**`CAS`** ：就是比较并交换，其作用是让 `CPU`比较内存中某个值是否和预期的值相同，如果相同则将这个值更新为新值，不相同则不做更新，也就是 `CAS` 是原子性的操作(读和写两者同时具有原子性)
`Java` 是在 `Unsafe` 类实现 `CAS` 的操作，`Java` 并没有在 `Unsafe` 类直接实现 `CAS` 的操作，**而是通过JDI本地调用C/C++语言来实现CAS操作的**


#### Atomic原子类有什么用？

**原子性意味着“一组操作要么全都操作成功，要么全都失败，不能只操作成功其中的一部分”**，主要作用是解决多线程下的线程不安全的问题（比如i++问题）。

原子类的作用和锁有类似之处，是为了保证并发情况下线程安全。不过原子类相比于锁，有一定的优势：

- **粒度更细** ：原子变量可以把竞争范围缩小到变量级别，通常情况下，锁的粒度都要大于原子变量的粒度。（锁通常是一段代码）

- **效率更高** ：除了高度竞争的情况之外，使用原子类的效率通常会比使用同步互斥锁的效率更高，因为原子类底层利用了 `CAS` 操作，不会阻塞线程


#### 能不能简单介绍一下AtomicInteger类的原理

`AtomicInteger` 类主要利用 `CAS (compare and swap)` + `volatile` 和 `native` 方法来保证原子操作，从而避免 `synchronized` 的高开销，执行效率大为提升。

`CAS` 的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。`UnSafe` 类的 `objectFieldOffset()` 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存偏移量，返回值是 `valueOffset` 。另外 `value` 是一个 `volatile` 变量，在内存中可见，因此 `JVM` 可以保证任何时刻任何线程总能拿到该变量的最新值

> valueOffset 是变量值在内存的偏移量，修改时直接根据内存偏移量拿到当前值，再比较，通过后直接更改内存中的值；volatile 保证了该变量的可见性，使操作具有load语义


#### CAS会带来哪些问题？能不能讲讲

CAS虽然高效的实现了原子性操作，但是也存在一些缺点，主要表现在以下三个方面
    
- **`ABA问题`** ： 在变量前面加上版本号，每次变量更新的时候变量的版本号都+1，即A->B->A就变成了1A->2B->3A，`AtomicStampedReference` 带有版本号的原子类

- **`循环时间长开销大`** ： 如果CAS操作失败，就需要循环进行CAS操作(循环同时将期望值更新为最新的)，如果长时间都不成功的话，那么会造成CPU极大的开销。**限制自旋次数，防止进入死循环**

- **`只能保证一个共享变量的原子操作`** 如果需要对多个共享变量进行操作，可以使用加锁方式(悲观锁)保证原子性，或者可以把多个共享变量合并成一个共享变量进行CAS操作


### ReentrantLock类

#### 介绍一下ReentrantLock

![markdown](https://ddmcc-1255635056.file.myqcloud.com/ab5d34a6-b390-4cde-955c-977a8b6e0926.png)

`ReentrantLock` 是基于 `AQS` 实现的对 **资源的公平与非公平独占锁**。通过重写 `AQS` 的 `tryAcquire` 和 `tryRelease` 方法实现的 `lock` 和 `unlock`与管理状态 `state`。

#### ReentrantLock是怎么实现可重入的？

在 `AQS` 中维护了两个变量：一个是 `state` 计数，一个是 `exclusiveOwnerThread` 拥有锁线程 。在获取锁时，先判断如果当前 `state > 0` 则说明锁已被获取，则判断获取锁的线程是不是当前线程，如果是则返回获取成功，并将 `state + 1`
当退出方法时 `state - 1`，直至 `state = 0`，则释放锁的占用，并设置 `exclusiveOwnerThread = null`


#### 说说公平锁与非公平锁

**公平锁在获取锁的时候会先判断当前是否有等待的队列**。而非公平不会判断是否有等待队列，直接尝试获取锁。有点像插队的感觉

非公平锁会有更好的性能。当然，非公平锁让获取锁的时间变得更加不确定，可能会导致在阻塞队列中的线程长期处于饥饿状态


### synchronized关键字


#### 讲一下synchronized关键字的底层原理

**synchronized 关键字底层原理属于 JVM 层面**，可以作用在 `实例方法`、`静态方法`、`代码块` 上。作用于实例方法时，锁对象为 **实例对象**；作用于静态方法时，锁对象为 **类对象**；作用于代码块时，可以指定锁对象。

- **`synchronized 同步语句块的情况`**

`synchronized` **同步语句块** 的实现使用的是 `monitorenter` 和 `monitorexit` 指令，其中 `monitorenter` 指令指向同步代码块的开始位置，`monitorexit` 
指令则指明同步代码块的结束位置，当执行 `monitorenter` 指令时，线程试图获取锁也就是获取 **对象监视器 monitor** 的持有权

>在 Java 虚拟机(HotSpot)中，Monitor 是基于 C++实现的，由ObjectMonitor实现的。每个对象中都内置了一个 ObjectMonitor对象。
>
>另外，wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因

在执行 `monitorenter` 时，会尝试获取对象的锁，如果锁的计数器为 0 则表示锁可以被获取，获取后将锁计数器设为 1 也就是加 1。

在执行 `monitorexit` 指令后，将锁计数器设为 0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止

- **`synchronized 同步方法的情况`**

`synchronized` 修饰的方法并没有 `monitorenter` 指令和 `monitorexit` 指令，取得代之的确实是 `ACC_SYNCHRONIZED` 标识，该标识指明了该方法是一个同步方法。`JVM` 通过该 `ACC_SYNCHRONIZED` 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用


**不管代码块还是同步方法两者的本质都是对对象监视器 monitor 的获取**


#### 谈谈synchronized和ReentrantLock的区别

- **两者都是可重入锁**

>“可重入锁” 指的是自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增 1，所以要等到锁的计数器下降为 0 时才能释放锁

- **synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API**

  - `synchronized` 是 `JVM` 层面实现的，并没有直接暴露给我们，会自动的获取和释放锁。

  - `ReentrantLock` 是 `JDK` 层面实现的（也就是 API 层面，需要手动 lock() 和 unlock() 方法配合 try/finally 语句块来完成锁的获取和释放），所以我们可以通过查看它的源代码，来看它是如何实现的

- **ReentrantLock 比 synchronized 增加了一些高级功能**

  - **等待可中断** : `ReentrantLock` 提供了一种能够中断等待锁的线程的机制，通过 `lock.lockInterruptibly()` 来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。

  - **可实现公平锁** : `ReentrantLock` 可以指定是公平锁还是非公平锁。而 `synchronized` 只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。`ReentrantLock` 默认情况是非公平的，可以通过 `ReentrantLock` 类的 `ReentrantLock(boolean fair)` 构造方法来制定是否是公平的。

  - **可实现选择性通知（锁可以绑定多个条件）**: `synchronized` 关键字与 `wait()` 和 `notify()/notifyAll()` 方法相结合可以实现等待/通知机制。`ReentrantLock` 类当然也可以实现，但是需要借助于 `Condition` 接口与 `newCondition()` 方法。

>Condition是 JDK1.5 之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify()/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” 


#### synchronized锁升级过程

**`1.6之前重量级锁实现`**

![markdown](https://ddmcc-1255635056.file.myqcloud.com/d4bfd6ec-9902-460d-bd58-39298ae52868.png)

`synchronized` 底层由 `ObjectMonitor`（对象监视器） 实现的。每个对象中都内置了一个 `ObjectMonitor` 对象。当线程试图获取锁时也就是获取对象监视器 `monitor` 的持有权。 **`重量级锁`** 获取过程：

- 有二个线程A、线程B，要进行操作的时候 ，发现方法上加了 `synchronized` 锁，这时线程调度到A线程执行，A线程就抢先拿到了锁。拿到锁的步骤为：

  - 将 `MonitorObject` 中的持有者（_owner）设置成 A线程，并将进入次数（_count） + 1

  - 将 `mark word` 设置为 `Monitor` 对象地址，锁标志位改为10；

  - 将B线程阻塞放到 `ContentionList` 队列

- JVM 每次从等待的尾部取出一个线程放到 `OnDeck` 作为候选者，但是如果并发比较高，等待队列会被大量线程执行CAS操作，为了降低对尾部元素的竞争，将等待队列拆分成 `ContentionList` 和 `EntryList` 二个队列, JVM将一部分线程移到 `EntryList` 作为准备进 `OnDeck` 的预备线程

- 作为 `_owner` 的A 线程执行过程中，可能调用 `wait` 释放锁，这个时候A线程进入 `Wait Set` , 等待被唤醒

**`引入便向锁和轻量级锁后锁升级过程`**

- `无锁状态到偏向锁`

![markdown](https://ddmcc-1255635056.file.myqcloud.com/e851e648-59ae-42b5-ac5a-5ea8f3979af9.png)

  - 首先A 线程访问同步代码块，使用CAS 操作将 Thread ID 放到 Mark Word 当中；

  - 如果CAS 成功，此时线程A 就获取了锁

  - 如果线程CAS 失败，证明有别的线程持有锁，例如上图的线程B 来CAS 就失败的，这个时候启动偏向锁撤销 （revoke bias）；

  - 锁撤销流程：

    - 让 A线程在全局安全点阻塞（类似于GC前线程在安全点阻塞） 
    - 遍历线程栈，查看是否有被锁对象的锁记录（ Lock Record），如果有Lock Record，需要修复锁记录和Markword，使其变成无锁状态。
    - 恢复A线程 - 将是否为偏向锁状态置为 0 ，开始进行轻量级加锁流程

- `便向锁到轻量级锁`

  - 线程在自己的栈桢中创建锁记录 `Lock Record`

  - 线程A 将 `Mark Word` 拷贝到线程栈的 `Lock Record` 中，这个位置叫 displayced hdr，如下图所示


![markdown](https://ddmcc-1255635056.file.myqcloud.com/5bb54bb2-3a9d-443d-b69d-f3819201daa3.png)

  - 将锁记录中的Owner指针指向加锁的对象（存放对象地址）

  - 将锁对象的对象头的MarkWord替换为指向锁记录的指针。这二步如下图所示：

![markdown](https://ddmcc-1255635056.file.myqcloud.com/6b6e4756-26f4-4b01-82fa-1175da18d67e.png)

  - 这时锁标志位变成 `00` ，表示轻量级锁


**轻量级锁什么时候会升级为重量级锁**

**当锁升级为轻量级锁之后，如果依然有新线程过来竞争锁，首先新线程会自旋尝试获取锁，尝试到一定次数（默认10次）依然没有拿到，锁就会升级成重量级锁**

>  一般来说，同步代码块内的代码应该很快就执行结束，这时候线程B 自旋一段时间是很容易拿到锁的，但是如果不巧，没拿到，自旋其实就是死循环，很耗CPU的，因此就直接转成重量级锁咯，这样就不用了线程一直自旋了。这就是锁膨胀的过程



### volatile关键字

#### 讲一下JMM

在 `JDK1.2` 之前，`Java` 的内存模型实现总是从主存（即共享内存）读取变量，是不需要进行特别的注意的。而在当前的 Java 内存模型下，线程可以把变量保存本地内存（比如cpu的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成 **数据的不一致**

这时就需要特殊指令，称为 `内存屏障`，以刷新本地缓存或使本地处理器缓存无效，以查看其他处理器的写入或使该处理器的写入对其它处理器可见。这些内存屏障通常在采取锁定和解锁操作时执行


#### happens-before是什么？

核心是 **前一个操作的结果对后续操作是可见的，这是 JMM 向程序员做出的保证**。但再不改变程序执行结果的前提下，编译器和处理器会对代码进行优化。也就是说两个操作之间存在 `happens-before` 规则 Java 并不一定按照规则定义的顺序来执行。 这么做的原因是因为我们程序员并不关心两个操作是否被重排序，只要保证程序执行时语义不能改变就好了

**1. 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前**

**2. 两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行。如果重排序之后的执行结果与按照happens-before关系来执行的结果一致，那么这种重排序并不非法**


- **`程序次序规则`：** 一段代码在单线程中执行的结果是有序的。注意是执行结果，因为虚拟机、处理器会对指令进行重排序（重排序后面会详细介绍）。虽然重排序了，但是并不会影响程序的执行结果，所以程序最终执行的结果与顺序执行的结果是一致的。故而这个规则只对单线程有效，在多线程环境下无法保证正确性。

- **`锁定规则`：** 这个规则比较好理解，无论是在单线程环境还是多线程环境，一个锁处于被锁定状态，那么必须先执行unlock操作后面才能进行lock操作。

- **`volatile变量规则`：** 这是一条比较重要的规则，它标志着volatile保证了线程可见性。通俗点讲就是如果一个线程先去写一个volatile变量，然后一个线程去读这个变量，那么这个写操作一定是happens-before读操作的。

- **`传递规则`：** 提现了happens-before原则具有传递性，即A happens-before B , B happens-before C，那么A happens-before C

- **`线程启动规则`：** 假定线程A在执行过程中，通过执行ThreadB.start()来启动线程B，那么线程A对共享变量的修改在接下来线程B开始执行后确保对线程B可见。

- **`线程终结规则`：** 假定线程A在执行的过程中，通过制定ThreadB.join()等待线程B终止，那么线程B在终止之前对共享变量的修改在线程A等待返回后可见


#### volatile关键字的作用？

>在 JDK1.2 之前，Java 的内存模型实现总是从主存（即共享内存）读取变量，是不需要进行特别的注意的。而在当前的 Java 内存模型下，线程可以把变量保存本地内存（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致


根据 `happens-before` 规则：如果一个线程先去写一个volatile变量，然后一个线程去读这个变量，那么这个写操作一定是happens-before读操作的

- **保证变量的可见性：变量声明为volatile，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取**

- **volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行**


#### 说说synchronized关键字和volatile关键字的区别？

- **原子性** : `synchronized` 可以保证代码片段的原子性。

- **可见性**

可见性指当一个线程修改共享变量的值，其他线程能够立即知道被修改了。Java是利用volatile关键字来提供可见性的。 当变量被volatile修饰时，这个变量被修改后会立刻刷新到主内存，当其它线程需要读取该变量时，会去主内存中读取新值。而普通变量则不能保证这一点。

除了 `volatile` 关键字之外，`final` 和 `synchronized` 也能实现可见性。

`synchronized`的原理是，在执行完，进入`unlock` 之前，必须将共享变量同步到主内存中。

`final` 修饰的字段，一旦初始化完成，如果没有对象逸出（指对象为初始化完成就可以被别的线程使用），那么对于其他线程都是可见的


- **有序性** 

在Java中，可以使用 `synchronized` 或者 `volatile` 保证多线程之间操作的有序性。实现原理有些区别：

`volatile` 关键字是使用内存屏障达到禁止指令重排序，以保证有序性。

`synchronized` 的原理是，一个线程lock之后，必须unlock后，其他线程才可以重新lock，使得被synchronized包住的代码块在多线程之间是串行执行的

### ThreadLocal类


#### 说说ThreadLocal类？作用？数据结构？

- **作用**

`ThreadLocal` 对象可以存储线程局部变量，每个线程 `Thread` 拥有一份自己的副本变量，多个线程互不干扰

- **数据结构**

`Thread` 类有一个类型为 `ThreadLocal.ThreadLocalMap` 的实例变量 `threadLocals` ，也就是说每个线程有一个自己的 `ThreadLocalMap。`

`ThreadLocalMap` 有自己的独立实现，可以简单地将它的 `key` 视作 `ThreadLocal`，`value` 为代码中放入的值（实际上key并不是ThreadLocal本身，而是它的一个弱引用）。

每个线程在往 `ThreadLocal` 里放值的时候，都会往自己的 `ThreadLocalMap` 里存，读也是以 `ThreadLocal` 作为 `key`，在自己的 `map` 里找对应的 `key`，从而实现了线程隔离。

`ThreadLocalMap` 有点类似 `HashMap` 的结构，只是 `HashMap` 是由数组+链表实现的，而 `ThreadLocalMap` 中并没有链表结构。
它内部是由一个 `Entry` 数组来实现的， 它的key是ThreadLocal<?> k ，继承自WeakReference， 也就是我们常说的弱引用类型，值则为我们存储的值


#### ThreadLocalMap哈希算法？怎么解决hash冲突？

**hash算法**

在 `ThreadLocal` 中有一个增量属性为 `HASH_INCREMENT = 0x61c88647`， 每当创建一个ThreadLocal对象，这个ThreadLocal.nextHashCode 这个值就会增长 `0x61c88647` 。
这个值很特殊，它是 **斐波那契数** 也叫 **黄金分割数**。`hash` 增量为 这个数字，带来的好处就是 `hash` 分布非常均匀。在数组中的索引通过 `hashcode & (length - 1)` 计算得到

**怎么解决hash冲突**

虽然 `ThreadLocalMap` 中使用了 **黄金分割数** 来作为 `hash` 计算因子，大大减少了 `Hash` 冲突的概率，但是仍然会存在冲突。
`HashMap` 中解决冲突的方法是在数组上构造一个链表结构，冲突的数据挂载到链表上，如果链表长度超过一定数量则会转化成红黑树。而 `ThreadLocalMap` 中并没有链表结构，所以这里不能适用 `HashMap` 解决冲突的方式

当往 `map` 中 `set` 时，会遍历当前的数组，直到 `Entry` 为空，有几种情况：

- 通过 `hash` 计算后的槽位对应的 `Entry` 数据为空：停止遍历，直接将数据放到该槽位

- 槽位数据不为空，`key` 值与当前计算获取的key值一致：**直接更新该槽位的数据**

- 槽位数据不为空，往后遍历过程中，在找到Entry为null的槽位之前，遇到 `key = null` 的Entry: 则开始替换过期数据逻辑，从 `key = null` 的槽位开始向后遍历，进行探测式数据清理工作


#### ThreadLocalMap扩容机制？

当容量超过 `threshold = len * 2 / 3` 即超过 `2/3` 时就开始执行 `rehash()`, 先进行探测式数据清理，然后在判断容量超过 `threshold - threshold / 4` 即当前容量超过一半时执行
`resize()`，**扩容后的大小为原来的两倍**


#### ThreadLocal内存泄露问题？源码是怎么解决的？为什么要用弱引用？

- `解决key内存泄露的问题`

ThreadLocal中，获取到线程私有变量是通过线程持有的一个threadLocalMap，然后传入ThreadLocal当做key获取到对象的，这时候就有个问题，如果你在使用完 ThreadLocal 之后，将其置为null，这时候这个对象并不能被回收，
因为他还有 ThreadLocalMap -> entry -> key的引用，直到该线程被销毁，但是这个线程很可能会被放到线程池中不会被销毁，这就产生了内存泄露。jdk是通过弱引用来解决的这个问题的，
entry中对key的引用是弱引用，当你取消了ThreadLocal的强引用之后，他就只剩下一个弱引用了，所以也会被回收。**所以弱引用主要用来解决key内存泄露的问题**

>弱引用在下一次GC时会被回收，不管内存是否足够


- `解决值内存泄露`


因为key是弱引用，在外部没有强引用的情况下，下一次GC时就会被回收，就会存在(null, value)的情况，又因为还有 ThreadLocalMap -> entry -> value的引用，直到该线程被销毁，但是这个线程很可能会被放到线程池中不会被销毁，这就产生了内存泄露
源码是通过在，`get`，`set`，`remove` 等方法时去检测删除过期的 `Entry` 即 null key 的


#### ThreadLocal使用场景？

**解决线程安全问题**


**传递线程上下文**


Queue` : 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。`


### 并发容器


#### ConcurrentHashMap

我们知道 `HashMap` 不是线程安全的，在并发场景下如果要保证一种可行的方式是使用 `Collections.synchronizedMap()` 方法来包装我们的 `HashMap`。但这是通过使用一个全局的锁来同步不同线程间的并发访问，因此会带来不可忽视的性能问题。

所以就有了 `HashMap` 的线程安全版本—— `ConcurrentHashMap` 的诞生。在 `ConcurrentHashMap` 中，无论是读操作还是写操作都能保证很高的性能：在进行读操作时(几乎)不需要加锁，而在写操作时通过锁分段技术只对所操作的段加锁而不影响客户端对其它段的访问。


#### CopyOnWriteArrayList

`CopyOnWriteArrayList` 类的所有可变操作（add，set 等等）都是通过创建底层数组的新副本（**浅拷贝**）来实现的。当 `List` 需要被修改的时候，我并不修改原有内容，而是对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了。

>所谓 `CopyOnWrite` 也就是说：在计算机，如果你想要对一块内存进行修改时，我们不在原有内存块中进行写操作，而是将内存拷贝一份，在新的内存中进行写操作，写完之后呢，就将指向原来内存指针指向新的内存，原来的内存就可以被回收掉了

**防止为了多线程同时修改，所以在 `add`，`remove` 等写的操作上，还是会做同步的**


#### ConcurrentLinkedQueue

`ConcurrentLinkedQueue` 是非阻塞队列。 阻塞队列可以通过加锁来实现，非阻塞队列可以通过 `CAS` 操作实现。

`ConcurrentLinkedQueue` 使用链表作为其数据结构，主要使用 `CAS` 非阻塞算法来实现线程安全。适合在对性能要求相对较高，同时对队列的读写存在多个线程同时进行的场景，即如果对队列加锁的成本较高则适合使用无锁的 `ConcurrentLinkedQueue` 来替代


#### ConcurrentSkipListMap

对于一个单链表，即使链表是有序的，如果我们想要在其中查找某个数据，也只能从头到尾遍历链表，这样效率自然就会很低，跳表就不一样了。跳表是一种可以用来快速查找的数据结构，有点类似于平衡树。它们都可以对元素进行快速的查找。但一个重要的区别是：对平衡树的插入和删除往往很可能导致平衡树进行一次全局的调整。而对跳表的插入和删除只需要对整个数据结构的局部进行操作即可。这样带来的好处是：在高并发的情况下，你会需要一个全局锁来保证整个平衡树的线程安全。而对于跳表，你只需要部分锁即可。这样，在高并发环境下，你就可以拥有更好的性能。而就查询的性能而言，跳表的时间复杂度也是 O(logn) 所以在并发数据结构中，JDK 使用跳表来实现一个 Map


>在 b+ 树索引中，索引页内的记录行使用了这种跳表的结构来提高查询速度


## 框架

### Spring Boot

### Spring

#### Spring事务有几种使用方式？

- **编程式事务管理**

通过 `TransactionTemplate` 或者 `TransactionManager` 手动管理事务，`TransactionTemplate` 是Spring提供对 `TransactionManager`的封装模板类，所以通常直接使用 `TransactionTemplate`


```java

@Autowired
private TransactionTemplate transactionTemplate;

public void testTransaction() {

        transactionTemplate.execute(new TransactionCallbackWithoutResult() {
            @Override
            protected void doInTransactionWithoutResult(TransactionStatus transactionStatus) {

                try {

                    // ....  业务代码
                } catch (Exception e){
                    //回滚
                    transactionStatus.setRollbackOnly();
                }

            }
        });
}
```


- **声明式事务管理**

推荐使用这种方式，代码侵入性最小，实际是通过 `AOP` 实现（基于@Transactional 的全注解方式使用最多）

```java
@Transactional(rollback = Exception.class)
public void aMethod {
    //do something
}
```
``

#### 有哪些事务失效的场景？




### MyBatis

### Spring Cloud

## 数据库


#### InnoDB存储引擎各组件介绍

![markdown](https://ddmcc-1255635056.file.myqcloud.com/d172f8cf-c7f1-4757-920b-9677ce4d1b77.png)

**连接器）**

连接器负责跟客户端`建立连接`、`校验账号`、`获取权限`、`维持和管理连接`。一旦连接成功，连接器会继续查出该连接所拥有的权限（例如：是否允许对 user 库的 t 表执行 select 语句）。这个连接后续的权限判断都依赖于此时读到的权限，这也就意味着一个用户成功连接后，即使修改了它的权限，也不会受影响，只有重新新建连接才会使用新的权限设置


**查询缓存）**

当接收到一个查询请求后，会先到查询缓存看看，当查询命中缓存，会立刻返回结果，跳过了 `解析`、`优化`、和`执行`阶段。如果未命中，就会继续后面执行阶段，执行完成后，执行结果会被存入查询缓存中

查询缓存以 key-value 的形式被直接缓存在内存中，这个key其实是一个大小写敏感哈希值，这个哈希值包括了语句本身、查询的数据库、参数等一些其它会影响查询结果的信息，即使只有一个字节的不同都会导致缓存不命中。当查询中包含任何用户自定义函数、存储函数、用户变量、临时表、mysq库中的系统表，或者任何包含列级别权限的表，都不会被缓存

查询缓存还会跟踪查询中涉及的每个表，如果这些表发生变化，那么和这个表相关的所有缓存数据都将失效，即使数据表变化时对缓存中的结果可能并没有影响。这也就是大多数情况下会建议不要使用查询缓存的原因，对于更新频繁的数据库来说，查询缓存命中率会非常低，除非是静态表，很少才有更新数据。mysql团队也意识到查询缓存的问题，自 **mysql 5.6（2013 年）以来，查询缓存已被默认禁用**，在 `mysql8.0` 版本中查询缓存模块直接被移除了


**语法解析器和预处理器**

- `语法解析器`

首先要提取关键字，比如 `select`，提出查询的表，提出字段名，提出查询条件等等。然后会验证是否使用错误的关键字，或者关键字使用顺序问题，再或者引号、括号前后能否正确匹配，之后生成一颗对应的 `“解析树”`。如果语句不对，就会收到 `“You have an error in your SQL syntax”` 的错误提醒

- `预处理器`

预处理器则根据一些规则进行进一步的检查解析树是否合法，例如 `检查数据表`、`数据列是否都存在`，解析 `名字和别名是否有歧义`。 **最后会验证权限**


**优化器）**

现在将由优化器将其转化为执行计划。一条语句可以有很多种执行的方式，虽然最后的查询结果都是相同的，优化器的作用就是找到这其中最好的方式

`mysql` 使用基于成本的优化器，它会 `预测` 一个查询使用某种执行计划时的成本，并选择其中成本最小的一个


**执行器）**

查询对应的执行计划就已经生成好了，执行器则根据这个执行计划来完成整个查询。开始执行的时候，会先判断这个表是否有权限，如果没有就直接返回权限错误（上查询缓存阶段，如果命中缓存，在返回缓存结果的时候也会做权限校验。在优化器之前也会做precheck权限校验）

执行器简单的根据执行计划的指令逐步执行，调用引擎的接口，返回接口执行的结果


#### 一条sql语句是如何执行的？

##### 查询语句

- 首先由连接器负责与客户端建立连接，然后检查该 `账号` 是否有权限，如果没有权限，直接返回错误信息，如果有权限，在 `MySQL8.0` 版本以前且开启缓存情况下，会先查询缓存，以这条 `sql` 语句为 `key的哈希值` 在内存中查询是否有结果，如果有直接缓存，如果没有，执行下一步。

- 通过 `解析器和预处理器` 进行词法分析，提取 `sql` 语句的关键元素，比如提取语句是查询 `select`，提取需要查询的 `表名` 为，需要查询所有的列，查询条件等。然后判断这个 `sql` 语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就生成 `解析树`。生成解析树之后还会对其进行验证，比如验证字段，表等是否存在，解析名字和别名是否有歧义等

- 接下来就是优化器进行确定执行方案，优化器根据自己的优化算法进行选择执行效率最好的一个方案（优化器认为，有时候不一定最好）。并生成执行计划后就准备开始执行了

- 执行器简单的根据执行计划的指令逐步执行。开始执行的时候，会先判断这个表是否有权限，如果没有就直接返回权限错误，如果有权限就会调用数据库引擎接口，返回引擎的执行结果

##### 更新语句

更新语句前面的步骤和查询一致，解析器通过解析知道这是一条更新语句，然后执行器选择最优执行计划去执行

- 执行器会先 `open table`，如果该表上有 `MDL（X）`（元数据排他锁），则等待。如果没有则在该表上加 MDL（S）（元数据共享锁） `-----> 服务层`

- 进入到引擎层，首先会去缓存里里的 `data dictionary` (元数据信息，是InnoDB自己管理的表缓存) 得到表信息，通过元数据信息，去 `lock info` 里查出是否会有相关的锁信息，并把这条update语句需要的锁信息写入到 `lock info` 里

- 然后涉及的旧数据以快照的形式存储到缓冲池中的 `undo page` 里，并在 `redo log` 中记录 `undo log`（undo log持久化）

- 然后对数据页进行修改，并把数据页的物理修改记录到 `redo log buffer（缓存）`里，同时将这个更新操作记录到 `redo log` 里面，此时 `redo log` 处于 `prepare` 状态，然后返回执行器可以提交了

还需要在二级索引上做的修改，写入到 `change buffer page`，等到下次有读取该二级索引页时，再去与二级索引页做 `merge`

- 执行器收到通知后记录 `binlog_cache`，同时修改的信息会按照 `event` 的格式，以不同的 `event type` 记录到 `binlog_cache` 中，在事务 `commit` 后 `dump` 线程会从 `binlog_cache` 里把 `event` 发送给 `slave` 的 `I/O` 线程

- 执行器调用引擎的提交事务接口，引擎把刚刚写入的 `redo log` 改成提交（commit）状态，更新完成


#### MyISAM和InnoDB的区别

- **对锁的支持**

`MyISAM` 只有表级锁(table-level locking)，而 `InnoDB` 支持行级锁(row-level locking)和表级锁，默认为行级锁

- **是否支持事务**

`MyISAM` 不提供事务支持。

`InnoDB` 提供事务支持，具有提交(commit)和回滚(rollback)事务的能力

- **是否支持外键**

`MyISAM` 不支持，而 `InnoDB` 支持


- **是否支持数据库异常崩溃后的安全恢复**

`MyISAM` 不支持，而 `InnoDB` 支持

使用 `InnoDB` 的数据库在异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态。这个恢复的过程依赖于 `redo log`


- **是否支持 MVCC**

`MyISAM` 不支持，而 `InnoDB` 支持


>MySQL InnoDB 引擎使用 **redo log(重做日志)** 保证事务的持久性，使用 **undo log(回滚日志)** 来保证事务的原子性
>
>MySQL InnoDB 引擎通过 **锁机制**、**MVCC** 等手段来保证事务的隔离性（ 默认支持的隔离级别是 `REPEATABLE-READ` ）。
>
>保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。


#### 自增值保存在哪里？用完了怎么办？


- `MyISAM` 引擎的自增值保存在数据文件中

- `InnoDB` 引擎的自增值到了 `MySQL 8.0` 版本后，才有了“自增值持久化”的能力，具体情况是：

  - 在 `MySQL 5.7` 及之前的版本，自增值保存在内存里，并没有持久化。每次重启后，第一次打开表的时候，都会去找自增值的最大值 max(id)，然后将 max(id)+1 作为这个表当前的自增值。﻿举例来说，如果一个表当前数据行里最大的 id 是 10，AUTO_INCREMENT=11。这时候，我们删除 id=10 的行，AUTO_INCREMENT 还是 11。但如果马上重启实例，重启后这个表的 AUTO_INCREMENT 就会变成 10。﻿也就是说，MySQL 重启可能会修改一个表的 AUTO_INCREMENT 的值。
  
  - 在 `MySQL 8.0` 版本，将自增值的变更记录在了 `redo log` 中，重启的时候依靠 `redo log` 恢复重启之前的值
  


**表定义的自增值达到上限后的逻辑是：再申请下一个 id 时，得到的值保持不变**，如果是主键在插入的时候就会报错了。

#### 怎么给线上的大表添加索引？

#### 说说Double-Write（解决什么问题，工作流程）

#### RR级别下会产生幻读吗？InnoDB是怎么解决的？

不会。在 `InnoDB` 存储引擎中，通过使用 `Next-key Lock` 算法来避免幻读的问题。在 `Next-Key Lock` 算法下，对于索引的扫描，不仅是锁住扫描到的索引，而且还锁住这些索引覆盖的范围(gap)。因此在这个范围内的插人都是不允许的。这样就避免了另外的事务在
这个范围内插人数据导致的幻读的问题。**因此, INNODB存储引聱的默认事务隔离级别是 `READ REPEATABLE` ，采用 `Next-key Lock` 算法,避免了幻读的现象**

**为什么RC级别下会产生幻读？**

因为在RC级别下仅使用了 `Record Lock` ，所以会导致

#### 什么是不可重复读？RR级别下是如何避免的？


#### 你是怎么优化数据库的？


### 索引


#### 索引有什么用？有什么缺点？

**索引是一种用于快速查询和检索数据的数据结构。常见的索引结构有: B 树， B+树和 Hash**

索引的作用就相当于目录的作用。打个比方: 我们在查字典的时候，如果没有目录，那我们就只能一页一页的去找我们需要查的那个字，速度很慢。如果有目录了，我们只需要先去目录里查找字的位置，然后直接翻到那一页就行了


##### 优点： 

- 使用索引可以大大加快 数据的检索速度（大大减少的检索的数据量）, 这也是创建索引的最主要的原因。

- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。

#### 缺点 ：

- 创建索引和维护索引需要耗费许多时间。当对表中的数据进行增删改的时候，如果数据有索引，那么索引也需要动态的修改，会降低 SQL 执行效率。

- 索引需要使用物理文件存储，也会耗费一定空间。

但是，**使用索引一定能提高查询性能吗?**

大多数情况下，索引查询都是比全表扫描要快的。但是如果数据库的数据量不大，那么使用索引也不一定能够带来很大提升


#### 介绍一下覆盖索引？什么是回表？

索引分为聚簇索引和二级索引，聚簇索引子节点为主键，叶子节点存的是数据行。二级索引子节点存的是索引键、叶子节点存的是主键

通常如果使用的是二级索引，会先在二级索引中查询符合的主键，然后再用主键去聚簇索引中查询其它列的数据或过滤，**这个过程称为回表**

但是如果查询的列和条件列都在二级索引上，那么可以直接提供查询结果，而不需要查询聚簇索引中的记录（mysql5.0或以下版本不支持），则被称为 **覆盖索引**


#### 索引的底层数据结构

##### Hash索引

哈希表是键值对的集合，通过键(key)即可快速取出对应的值(value)，因此哈希表可以快速检索数据（接近 O（1））。

通过哈希算法，我们可以快速找到 `value` 对应的 `index`，找到了 `index` 也就找到了对应的 `value`。但哈希算法有 `Hash` 冲突问题，也就是说多个不同的 `key` 最后得到的 `index` 相同。通常情况下，我们常用的解决办法是 **链地址法**。链地址法就是将哈希冲突数据存放在链表中

既然哈希表这么快，为什么MySQL **没有使用其作为索引的数据结构呢？**

1. **Hash 冲突问题** ：我们上面也提到过Hash 冲突了，不过对于数据库来说这还不算最大的缺点。

2. **Hash 索引不支持顺序和范围查询** (Hash 索引不支持顺序和范围查询是它最大的缺点： 假如我们要对表中的数据进行排序或者进行范围查询，那 Hash 索引可就不行了


##### **`B+ tree索引`**

在 `InnoDB` 中，**每一个索引都会单独维护一棵索引树** ，又分为聚簇索引和二级索引

`聚簇索引` 是按照表 `主键` 构造的，树中同时保存了索引和数据行，数据行被存放在索引的叶子节点中。也将聚簇索引的叶子节点称为数据页。因为无法同时把数据行存放在两个不同的地方，所以一个表只能有一个 `聚簇索引`。 **如果没有定义主键，`InnoDB` 会选择一个唯一非空索引字段代替，如果没有这样的索引，那么 `InnoDB`会隐式定义一个 `6` 字节的 `rowId` 来作为 `聚簇索引` **

除了聚簇索引其它的都是二级索引，和聚簇索引不同的是：二级索引叶子节点存的是主键的值，非叶子节不存储数据行，只存储指向下层叶子的指针和索引键值的虚记录

> 虚记录：并不存在于数据表中的记录


为了减少IO次数，存储引擎会整页整页的读取索引记录，并且索引页都是固定大小的，对于 `InnoDB` 默认为 `16kb`。这也是 `索引字段越小越好` 的原因：因为磁盘块的大小也就是一个数据页的大小，
是固定的（默认16k），那么在总数据量固定的情况下，如果数据项占的空间越小，则每页能存的数据项数量越多，那么树的高度越低。这也是为什么 `b+` 树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，每个磁盘块的数据项会大幅度下降，导致树增高


索引页之间通过双向链表链接（Page Header中的PAGE_PREV和PAGE_NEXT记录上、下页的位置），页按照索引键的顺序排序；另外每个页中的记录也是通过单向链表进行维护的（Recorder Header的最后两个字节记录下一行偏移量）。**按照索引键排序的好处就是对于索引键的排序查找和范围查找非常快**，只需要查找对应符合的值，如果判断不满足，可以立即结束查询，不需要继续查找。如果没有排好序的话，则需要全表遍历

在索引页内部记录查找中，使用的类似 `跳表` 查找，在定位到页后，会先利用页目录（Page Directory）来进行 `二分查找`，定位到距离数据较近的槽点（Slot），然后再遍历链表


#### B树和B➕树两者有何异同呢？

- `B` 树的所有节点既存放键(key) 也存放 数据(data)；而 B+树只有叶子节点存放 `key` 和 `data`，其他内节点只存放 `key`

- `B` 树的叶子节点都是独立的; B+树的叶子节点有一条引用链指向与它相邻的叶子节点

- `B` 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了；而 B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。


#### 为什么用b➕tree来做索引？

- **减少IO次数**：`B+Tree` 树非叶子节点只存储 `key` 值，因此相对于 `B-Tree` 节点可以存储更多的数据，每次读入内存的 `key` 值就更多，相对来说 `I/O` 次数就降低

- **查询效率稳定**：任何数据的查找都是必须从叶子节点到非叶子节点，所以说每个数据查找的效率几乎都是相同的

- **索引/数据有序**：只需要遍历叶子节点就可以对所有的 `key` 进行扫描，有序在范围查找时和排序查找时效率更高


#### 为什么索引列越小越好？

因为索引页是固定大小的，默认为16k，索引列越小每页能放的记录就越多，这样每次IO读取的就越多，可以减少IO次数


#### 为什么建议主键越小越好？

- 在二级索引中，叶子节点存储的是主键，如果主键越小，那么索引所占用的空间也就会越小

- 在聚簇索引中，主键作为索引的key，如果key越小每页能放的记录就越多，这样每次IO读取的就越多，可以减少IO次数


#### 说说页合并和页分裂？

##### 页分裂

`B+` 树为了维护索引有序性，在插入新值的时候需要做必要的维护。如果插入的位置在页中间，则需要 **`逻辑上`** 挪动前后的数据（改变指向下一数据行的指针）。更糟糕的情况是，
如果所在数据页的数据已经满了，根据 `B+` 树的算法需要新建一个新的页，然后挪动部分数据过去并在 `逻辑上` 挪动相关页的顺序，这个过程中性能肯定会受到影响

除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 `50%`。**页分裂发生在插入数据或更新数据**


##### 页合并

**删除记录时，不会实际删除该记录。相反，它将记录标记为已删除，并且它所使用的空间可以被其它记录声明使用**。当页中删除的记录达到 `MERGE_THRESHOLD`（默认页体积的50%），InnoDB会开始寻找最靠近的页（前或后）看看是否可以将两个页合并以优化空间使用（被合并页体积也需要小于50%）,
合并后，相邻的页变成一个空页，可以接纳新数据

当我们进行UPDATE操作，并且使页中记录数量低于阈值时，InnoDB也会进行一样的操作

规则是：**页合并发生在删除或更新操作中，关联到当前页的相邻页**

另一方面，要记住在合并和分裂的过程，InnoDB会在索引树上加写锁（x-latch）。在操作频繁的系统中这可能会是个隐患。它可能会导致索引的锁争用（index latch contention）。如果表中没有合并和分裂（也就是写操作）的操作，称为“乐观”更新，只需要使用读锁（S）。带有合并也分裂操作则称为“悲观”更新，使用写锁（X）

#### 为什么通常建议自增列作为主键？

##### `性能上`

用自增列作为主键 ，这样可以保证数据行是按顺序写入的，每次插入都是追加操作，当达到页的最大填充因子时（InnoDB默认最大填充因子是页大小的 15/16，留出部分空间用于后续修改），
下一条记录就会写入新的页中。不涉及到挪动其它记录，也不会触发叶子节点的分裂

而有业务逻辑的字段做主键或者使用UUID，则不能保证有序插入，这样写入数据的成本相对较高。**总结以下是一些缺点：**

- 写入目标页可能已经刷到磁盘上并从缓存中清除，或者是还没有被加载到缓存中，InnoDB在插入之前不得不先找到并从磁盘读取目标页到内存。这将导致大量的随机I/O

- 因为写入是乱序的，InnoDB不得不频繁地做页分裂操作，以便为新的行分配空间，页分裂会导致移动大量的数据，一次插入最少需要修改三个页而不是一个页

- 由于频繁的页分裂，页会变得稀疏并被不规则的填充，最终数据会有碎片

##### `空间上`

而且通常业务主键都比较大，比如用身份证号做主键，那么每个二级索引的叶子节点都需要存储，这也大大的增加了索引的空间占用。而如果使用整型做主键，则只需4个字节，长整型（bigint）也只需8字节。所以，从性能和存储空间方面考量，自增主键往往是更合理的选择


#### 建立索引的一些原则

##### **`最左前缀匹配原则`**

- 如果不是按照索引的最左列开始查找，则无法使用索引

- 不能跳过索引中的列

- 如果查询中有某个列是范围查询，则其右边所有列都无法使用索引


##### **`尽量选择区分度高的列作为索引`**

区分度的公式是 `count(distinct col) / count(*)`，表示字段不重复的比例，比例越大查询效率越高


##### **`尽量的扩展索引，不要新建索引`**

- 空间：InnoDB 会为每个索引都建立 B+ 树索引，所以会占用更多的空间

- 性能：每次修改数据时要对索引进行维护，多棵索引树无疑增加了维护成本。并且在查询上，多列索引有机会使用 覆盖索引 和 索引下推 来提升查询效率


#### 使用索引的注意事项

##### **索引失效情况**

- 索引列不能参与计算：比如 from_unixtime(create_time) = ’2014-05-29’ 或 left(code, 6) = ‘010108’ 或 score + 1 = 80 就不能使用到索引。所以语句应该写成create_time = unix_timestamp(’2014-05-29’) 和 code LIKE ‘010108%’

- 索引列与参数类型不匹配：比如字符串字段索引 phone = 13024532432

- 最左前缀匹配：比如左模糊查询


##### 被频繁更新的字段应该慎重建立索引

虽然索引能带来查询上的效率，但是每个索引都会单独维护索引树，维护索引的成本也是不小的。 如果一个字段不被经常查询，反而被经常修改，那么就更不应该在这种字段上建立索引了


### 锁

#### InnoDB引擎的行锁是怎么实现的？

InnoDB 通过给索引项加锁来实现行锁，如果没有索引，则通过隐藏的聚簇索引来对记录加锁。如果操作不通过索引条件检索数据，InnoDB 则对表中的所有记录加锁，实际效果就和表锁一样


#### InnoDB存储引擎的锁的算法

`InnoDB` 存储引擎有3种行锁的算法，分别是：

 - `Record Lock`: 单个记录上的锁
 
- `Gap Lock`: 间隙锁，锁定一个范围，但不包括本记录

- `Next-Key Lock`: **Gap Lock + Record Lock**，锁定一个范围，并且锁定记录本身

`InnoDB ` 对于行的查询都是默认采用 `Next-Key lock` 算法。当条件索引是唯一索引时，`InnoDB` 存储引擎会进行优化，将其降级为 `Record Lock`，即锁住索引本身 ，而不是范围，从而提高并发性。若是通过辅助索引查询，不但会给辅助索引加锁，还会为聚集索引上锁。对于辅助索引加 `Next-Key Lock`，而聚集索引因为是唯一的，所以只会加 `Record Lock`

对于没有显示创建索引的表，则会对 `rowId` 的聚集索引来加锁。如果操作未使用索引查询，那么会对表中所有记录加锁，实际效果和表锁一样


#### 数据库的乐观锁和悲观锁是什么？怎么实现的？

- `悲观锁`

在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）

在悲观锁的情况下，为了保证事务的隔离性，就需要 **一致性锁定读**。读取数据时给加锁，其它事务无法修改这些数据。修改删除数据时也要加锁，其它事务无法读取这些数据

- `乐观锁(一致性非锁定读)`

相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性

而乐观锁机制在一定程度上解决了这个问题。乐观锁，大多是基于数据版本（ Version ）记录机制实现。在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据


#### 什么是死锁？怎么解决？



### 事务与MVCC

#### 事务的四种隔离级别

- **未提交读(Read Uncommitted)** ：允许脏读，也就是可能读取到其他会话中未提交事务修改的数据，**任何操作都不会加锁**

- **提交读(Read Committed)** ：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读)，**RC级别中，数据的读取都是不加锁的（采用一致性非锁定读），但是数据的写入、修改和删除是需要加锁的（仅使用Record Lock）**

- **可重复读(Repeated Read)** ：可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，~~但是还存在幻象读~~（RR级别中通过Next-Key Lock和MVCC解决了幻读），**在 RR 隔离级别下，对于读 `InnoDB` 存储引擎同样使用 一致性非锁定读 ，但加锁上却和RC不同，其使用 `Next-Key Lock`**

- **串行读(Serializable)** ：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞


#### InnoDB如何实现事务的ACID的？

- MySQL `InnoDB` 引擎使用 `redo log(重做日志)` 保证事务的持久性；

- 使用 `undo log(回滚日志)` 来保证事务的原子性；

- MySQL `InnoDB` 引擎通过 `锁机制`、`MVCC` 等手段来保证事务的隔离性（ 默认支持的隔离级别是 REPEATABLE-READ ）。

- 保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障


#### MVCC在InnoDB中的实现

`MVCC` 的实现依赖于：**隐藏字段、Read View、undo log**。在内部实现中，`InnoDB` 通过数据行的 `DB_TRX_ID` 和 `Read View` 来判断数据的可见性，如不可见，则通过数据行的 `DB_ROLL_PTR` 找到 `undo log` 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 `Read View` 之前已经提交的修改和该事务本身做的修改



#### 隐藏字段

在内部，`InnoDB` 存储引擎为每行数据添加了三个 [隐藏字段](https://dev.mysql.com/doc/refman/5.7/en/innodb-multi-versioning.html)：

- `DB_TRX_ID（6字节）`：表示最后一次插入或更新该行的事务id。此外，`delete` 操作在内部被视为更新，只不过会在记录头 `Record header` 中的 `deleted_flag` 字段将其标记为已删除
- `DB_ROLL_PTR（7字节）` 回滚指针，指向该行的 `undo log` 。如果该行未被更新，则为空
- `DB_ROW_ID（6字节）`：如果没有设置主键且该表没有唯一非空索引时，`InnoDB` 会使用该id来生成聚簇索引



#### ReadView

[`Read View`](https://github.com/facebook/mysql-8.0/blob/8.0/storage/innobase/include/read0types.h#L298) 主要是用来做可见性判断，里面保存了 “当前对本事务不可见的其他活跃事务”

主要有以下字段：

- `m_low_limit_id`：目前出现过的最大的事务ID+1，即下一个将被分配的事务ID。大于这个ID的数据版本均不可见
- `m_up_limit_id`：活跃事务列表 `m_ids` 中最小的事务ID，如果 `m_ids` 为空，则 `m_up_limit_id` 为 `m_low_limit_id`。小于这个ID的数据版本均可见
- `m_ids`：`Read View` 创建时其他未提交的活跃事务ID列表。创建 `Read View `时，将当前未提交事务ID记录下来，后续即使它们修改了记录行的值，对于当前事务也是不可见的。`m_ids` 不包括当前事务自己和已提交的事务（正在内存中）
- `m_creator_trx_id`：创建该 `Read View` 的事务ID



#### undo-log

`undo log` 主要有两个作用：

- 当事务回滚时用于将数据恢复到修改前的样子
- 另一个作用是 `MVCC` ，当读取记录时，若该记录被其他事务占用或当前版本对该事务不可见，则可以通过 `undo log` 读取之前的版本数据，以此实现非锁定读



**在 `InnoDB` 存储引擎中 `undo log` 分为两种： `insert undo log` 和 `update undo log`：**



1. **`insert undo log`** ：指在 `insert` 操作中产生的 `undo log`。因为 `insert` 操作的记录只对事务本身可见，对其他事务不可见，故该 `undo log` 可以在事务提交后直接删除。不需要进行 `purge` 操作



**`insert` 时的数据初始状态：**

![markdown](https://ddmcc-1255635056.file.myqcloud.com/317e91e1-1ee1-42ad-9412-9098d5c6a9ad.png)

2. **`update undo log`** ：`update` 或 `delete` 操作中产生的 `undo log`。该 `undo log`可能需要提供 `MVCC` 机制，因此不能在事务提交时就进行删除。提交时放入 `undo log` 链表，等待 `purge线程` 进行最后的删除



**数据第一次被修改时：**



![markdown](https://ddmcc-1255635056.file.myqcloud.com/c52ff79f-10e6-46cb-b5d4-3c9cbcc1934a.png)

**数据第二次被修改时：**



![markdown](https://ddmcc-1255635056.file.myqcloud.com/6a276e7a-b0da-4c7b-bdf7-c0c7b7b3b31c.png)

不同事务或者相同事务的对同一记录行的修改，会使该记录行的 `undo log` 成为一条链表，链首就是最新的记录，链尾就是最早的旧记录



#### 数据可见性算法

在 `InnoDB` 存储引擎中，创建一个新事务后，执行每个 `select` 语句前，都会创建一个快照（Read View），**快照中保存了当前数据库系统中正处于活跃（没有commit）的事务的ID号**。其实简单的说保存的是系统中当前不应该被本事务看到的其他事务ID列表（即m_ids）。当用户在这个事务中要读取某个记录行的时候，`InnoDB` 会将该记录行的 `DB_TRX_ID` 与 `Read View` 中的一些变量及当前事务ID进行比较，判断是否满足可见性条件

[具体的比较算法](https://github.com/facebook/mysql-8.0/blob/8.0/storage/innobase/include/read0types.h#L161)如下：[图源](https://leviathan.vip/2019/03/20/InnoDB%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%88%86%E6%9E%90-MVCC/#MVCC-1)

![markdown](https://ddmcc-1255635056.file.myqcloud.com/8778836b-34a8-480b-b8c7-654fe207a8c2.png)

1. 如果记录 DB_TRX_ID < m_up_limit_id，那么表明最新修改该行的事务（DB_TRX_ID）在当前事务创建快照之前就提交了，所以该记录行的值对当前事务是可见的

2. 如果 DB_TRX_ID >= m_low_limit_id，那么表明最新修改该行的事务（DB_TRX_ID）在当前事务创建快照之后才修改该行，所以该记录行的值对当前事务不可见。跳到步骤5

3. m_ids 为空，则表明在当前事务创建快照之前，修改该行的事务就已经提交了，所以该记录行的值对当前事务是可见的

4. 如果 m_up_limit_id <= DB_TRX_ID < m_up_limit_id，表明最新修改该行的事务（DB_TRX_ID）在当前事务创建快照的时候可能处于“活动状态”或者“已提交状态”；所以就要对活跃事务列表 m_ids 进行查找（源码中是用的二分查找，因为是有序的）

    - 如果在活跃事务列表 m_ids 中能找到 DB_TRX_ID，表明：①在当前事务创建快照前，该记录行的值被事务ID为 DB_TRX_ID 的事务修改了，但没有提交；或者 ②在当前事务创建快照后，该记录行的值被事务ID为 DB_TRX_ID 的事务修改了。这些情况下，这个记录行的值对当前事务都是不可见的。跳到步骤5

    - 在活跃事务列表中找不到，则表明“id为trx_id的事务”在修改“该记录行的值”后，在“当前事务”创建快照前就已经提交了，所以记录行对当前事务可见

5. 在该记录行的 DB_ROLL_PTR 指针所指向的 `undo log` 取出快照记录，用快照记录的 DB_TRX_ID 跳到步骤1重新开始判断，直到找到满足的快照版本或返回空


#### 在RC和RR隔离级别下MVCC的差异？

在RC和RR级别下，`InnoDB` 都会使用 **一致性非锁定读（MVCC）** ，区别是快照的获取时机不同：

- **RC级别**：在 `Read Committed` 级别下，事务中 **`每一次`** 一致性读取（普通select）都会获取新的快照（ReadView）


- **RR级别**：如果事务隔离级别为 `Repeatable Read`（默认级别），只有在事务开始之后 **`第一次`** 执行一致性读取（普通select）才会去获取快照（ReadView），并且后面每次查询都会以这份快照为准，直至事务结束


#### RR级别下会发生幻读吗？为什么？

在 `Repeatable Read` 级别下不会发生幻读。在执行普通 `select` 语句时，使用的是 **一致性非锁定读（MVCC、快照读）** ，会根据第一次查询生成的活跃事务ID列表来判断数据可见性。
所以在第一次查询之后变更的数据是不可见的，解决了一致性非锁定读下的幻读问题

`MVCC` 解决了快照读下的幻读问题，但是对于 **锁定读**，每一次读取即使在同一事务中，也会设置和读取自己的新快照，所以读取的都是最新的数据。这样就会产生幻读的问题

`InnoDB` 使用 `Next-Key Lock` 来锁住记录本身和前后间隙，使其它事务不能插入数据，来解决幻读的问题 


## Redis

#### Redis常见数据结构

- **`string`**

- **`list`** ：`Redis` 的 `list` 的实现为一个 **双向链表**，即可以支持反向查找和遍历：发布与订阅或者说消息队列

- **`hash`** ：`hash` 类似于 **JDK1.8** 前的 `HashMap`，内部实现也差不多(数组 + 链表)。不过，`Redis` 的 `hash` 做了更多优化。另外，`hash` 是一个 `string` 类型的 field 和 value 的映射表，特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值

- **`set`** ：`set` 类似于 Java 中的 `HashSet` 。`Redis` 中的 `set` 类型是一种无序集合，集合中的元素没有先后顺序。当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作

- **`sorted set`** ：和 `set` 相比，`sorted set` 增加了一个权重参数 `score`，使得集合中的元素能够按 `score` 进行有序排列，还可以通过 `score` 的范围来获取元素的列表

- **`bitmap`** ：bitmap 存储的是连续的二进制数字（0 和 1），通过 bitmap, 只需要一个 bit 位来表示某个元素对应的值或者状态，key 就是对应元素本身 。我们知道 8 个 bit 可以组成一个 byte，所以 bitmap 本身会极大的节省储存空间


#### Redis单线程模型

- Redis 基于 Reactor 模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）。文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据 套接字目前执行的任务来为套接字关联不同的事件处理器。

- 当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。

- 虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。


#### Redis没有使用多线程？为什么不使用多线程？

但如果严格来讲从Redis4.0之后并不是单线程，除了主线程外，它也有后台线程在处理一些较为缓慢的操作，例如清理脏数据、无用连接的释放、大 key 的删除等等。大体上来说，Redis 6.0 之前主要还是单线程处理

我觉得主要原因有下面 3 个：

- 单线程编程容易并且更容易维护；
- Redis 的性能瓶颈不再 CPU ，主要在内存和网络；
- 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能


#### Redis6.0之后为何引入了多线程？

**Redis6.0 引入多线程主要是为了提高网络 IO 读写性能** ，因为这个算是 `Redis` 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。

虽然，Redis6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了， 执行命令仍然是单线程顺序执行。因此，你也不需要担心线程安全问题。
Redis6.0 的多线程默认是禁用的


#### 为什么要用Redis、为什么要用缓存？

**高性能：**
保证用户下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。不过，要保持数据库和缓存中的数据的一致性。 如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可！
    
**高并发：**

直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。进而，我们也就提高的系统整体的并发


#### Redis是如何判断数据是否过期的呢？

`Redis` 通过一个叫做 **过期字典**（可以看作是 `hash` 表）来保存数据过期的时间。过期字典的键指向 `Redis` 数据库中的某个 key(键)，过期字典的值是一个 long long 类型的整数，这个整数保存了 `key` 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）


#### 过期的数据的删除策略了解么？

- **惰性删除** ：只会在取出 key 的时候才对数据进行过期检查。这样对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。

- **定期删除** ： 每隔一段时间抽取一批 key 执行删除过期 key 操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响。


定期删除对内存更加友好，惰性删除对 CPU 更加友好。两者各有千秋，所以 Redis 采用的是 定期删除+惰性/懒汉式删除


#### Redis持久化机制

**Redis 的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file, AOF）**

- **`RDB（默认）`**

Redis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用

> RDB配置方式：save `<seconds>` `<changes>`
>
>其中，`<seconds>` 表示每隔多少秒执行一次快照，`<changes>` 表示修改了多少次数据后执行快照
>
>默认配置为：
> 
>save 900 1
>
>save 300 10
>
>save 60 10000
>
>表示 900秒内如果有1次/300秒内有10次/60秒内有10000次的变更，则创建快照
    
- **`AOP`**

与快照持久化相比，`AOF` 持久化 的实时性更好，因此已成为主流的持久化方案。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化 开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入硬盘中的 AOF 文件
    
>appendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度
>
>appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘
>
>appendfsync no        #让操作系统决定何时进行同步      

让 `Redis` 每秒同步一次 `AOF` 文件，`Redis` 性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，`Redis` 还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。


#### Redis事务

使用 `MULT` 命令后可以输入多个命令。`Redis` 不会立即执行这些命令，而是将它们放到队列，当调用了EXEC命令将执行所有命令.你也可以通过 `DISCARD`  命令取消一个事务，它会清空事务队列中保存的所有命令
Redis 是不支持 `roll back` 的


#### 什么是缓存穿透？

缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层

**有哪些解决办法？**

- **缓存无效 key** ：这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 
    
- **`布隆过滤器`**
        
通过它我们可以非常方便地判断一个给定数据是否存在于海量数据中。我们需要的就是判断 `key` 是否合法
        
**具体是这样做的** ：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程
            
1）我们先来看一下，**当一个元素加入布隆过滤器中的时候，会进行哪些操作：**

- 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。

- 根据得到的哈希值，在位数组中把对应下标的值置为 1。


2）我们再来看一下，**当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行哪些操作：**

- 对给定元素再次进行相同的哈希计算；

- 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。

然后，一定会出现这样一种情况：不同的字符串可能哈希出来的位置相同。 （可以适当增加位数组大小或者调整我们的哈希函数来降低概率）


#### 什么是缓存雪崩？

**缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求(`缓存服务器奔溃`)，有一些被大量访问数据（`热点缓存`）在某一时刻大面积失效，导致对应的请求直接落到了数据库上**

- 针对 Redis 服务不可用的情况：
  - 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。
  - 限流，避免同时处理大量的请求。

- 针对热点缓存失效的情况：
  - 设置不同的失效时间比如随机设置缓存的失效时间。
  - 缓存永不失效。
  
  
#### 缓存一致性

一般会采用先删除缓存再更新数据库或先更新数据库再删除缓存，

- **第一种先删除在更新：** 你删除了缓存，这时有读的请求发现没缓存，去数据库查询后放入缓存，这时数据库在被更新，导致缓存和数据库不一致。这种情况可以使用双删的策略，就是一开始先删除一次，完后执行完业务，在删除一次。还有就是先更新数据库在删除缓存，这种好处就是保证我更新完缓存也是失效的

- **第二种先更新数据库，再删缓存**

    一般是推荐这种，首先因为删除缓存比更新数据库快的多，这段时间内会读到脏数据的可能性就越小，当然也是存在产生数据不一致的可能性的，比如读操作比写操作还慢，写完数据删除缓存都返回了，读请求才把读出来的脏数据写入缓存。不过这种可能性比较小
不管是先删缓存再更新数据库还是先更新数据库再删缓存，如果删除缓存失败了都会导致缓存跟数据不一致问题！

**保证删除缓存操作的可靠性**

- 消息队列，确保消息删除
    
- 专门程序+消息队列 确保消息删除


## docker

#### docker常见命令

**`查看`**
	
- `docker images`： 列出所有镜像(images)

- `docker ps`：	 列出正在运行的容器(containers)

- `docker ps -a`:  列出所有的容器

- `docker pull <image_name>`：  下载镜像

- `docker top <id、container_name>`：查看容器内部运行程序

- `docker logs <id、container_name>`：查看容器日志

**`容器`**
	
- `docker exec -it <id、container_name> /bin/bash`：进入容器

- `docker exec -it /bin/sh`：进入alpine类容器的sh

- `docker stop <id、container_name>`: 停止一个正在运行的容器

- `docker start <id、container_name>`：启动一个已经停止的容器

- `docker restart <id、container_name>`: 重启容器

- `docker rm <id、container_name>`：删除容器

- `docker run -i -t -p :80 LAMP /bin/bash`:	运行容器并做http端口转发

- `docker rm docker ps -a -q`：删除所有已经停止的容器

- `docker kill $(docker ps -a -q)`：杀死所有正在运行的容器，$()功能同``

**`镜像`**

- `docker history <image_name>`：显示一个镜像的历史	
	
- `docker build -t <image_name:tag> .`：构建1个镜像, -t(镜像的名字及标签) <id、container_name>(镜像名) .(构建的目录)

- `docker run -i -t <image_name>`：	-t -i以交互伪终端模式运行，可以查看输出信息

- `docker run -d -p 80:80 <image_name>`：镜像端口 -d后台模式运行镜像

- `docker rmi <image_id>`：删除镜像

- `docker rmi $(docker images -q)`：删除所有镜像

- `docker rmi $(sudo docker images --filter "dangling=true" -q --no-trunc)`：删除无用镜像


#### docker-compose怎么挂载磁盘

```dockerfile
 volumes:
   - <宿主机>:<容器>
```