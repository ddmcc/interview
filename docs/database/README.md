
#### InnoDB存储引擎各组件介绍

![markdown](https://ddmcc-1255635056.file.myqcloud.com/d172f8cf-c7f1-4757-920b-9677ce4d1b77.png)

**连接器）**

连接器负责跟客户端`建立连接`、`校验账号`、`获取权限`、`维持和管理连接`。一旦连接成功，连接器会继续查出该连接所拥有的权限（例如：是否允许对 user 库的 t 表执行 select 语句）。这个连接后续的权限判断都依赖于此时读到的权限，这也就意味着一个用户成功连接后，即使修改了它的权限，也不会受影响，只有重新新建连接才会使用新的权限设置


**查询缓存）**

当接收到一个查询请求后，会先到查询缓存看看，当查询命中缓存，会立刻返回结果，跳过了 `解析`、`优化`、和`执行`阶段。如果未命中，就会继续后面执行阶段，执行完成后，执行结果会被存入查询缓存中

查询缓存以 key-value 的形式被直接缓存在内存中，这个key其实是一个大小写敏感哈希值，这个哈希值包括了语句本身、查询的数据库、参数等一些其它会影响查询结果的信息，即使只有一个字节的不同都会导致缓存不命中。当查询中包含任何用户自定义函数、存储函数、用户变量、临时表、mysq库中的系统表，或者任何包含列级别权限的表，都不会被缓存

查询缓存还会跟踪查询中涉及的每个表，如果这些表发生变化，那么和这个表相关的所有缓存数据都将失效，即使数据表变化时对缓存中的结果可能并没有影响。这也就是大多数情况下会建议不要使用查询缓存的原因，对于更新频繁的数据库来说，查询缓存命中率会非常低，除非是静态表，很少才有更新数据。mysql团队也意识到查询缓存的问题，自 **mysql 5.6（2013 年）以来，查询缓存已被默认禁用**，在 `mysql8.0` 版本中查询缓存模块直接被移除了


**语法解析器和预处理器**

- `语法解析器`

首先要提取关键字，比如 `select`，提出查询的表，提出字段名，提出查询条件等等。然后会验证是否使用错误的关键字，或者关键字使用顺序问题，再或者引号、括号前后能否正确匹配，之后生成一颗对应的 `“解析树”`。如果语句不对，就会收到 `“You have an error in your SQL syntax”` 的错误提醒

- `预处理器`

预处理器则根据一些规则进行进一步的检查解析树是否合法，例如 `检查数据表`、`数据列是否都存在`，解析 `名字和别名是否有歧义`。 **最后会验证权限**


**优化器）**

现在将由优化器将其转化为执行计划。一条语句可以有很多种执行的方式，虽然最后的查询结果都是相同的，优化器的作用就是找到这其中最好的方式

`mysql` 使用基于成本的优化器，它会 `预测` 一个查询使用某种执行计划时的成本，并选择其中成本最小的一个


**执行器）**

查询对应的执行计划就已经生成好了，执行器则根据这个执行计划来完成整个查询。开始执行的时候，会先判断这个表是否有权限，如果没有就直接返回权限错误（上查询缓存阶段，如果命中缓存，在返回缓存结果的时候也会做权限校验。在优化器之前也会做precheck权限校验）

执行器简单的根据执行计划的指令逐步执行，调用引擎的接口，返回接口执行的结果


#### 一条sql语句是如何执行的？

##### 查询语句

- 首先由连接器负责与客户端建立连接，然后检查该 `账号` 是否有权限，如果没有权限，直接返回错误信息，如果有权限，在 `MySQL8.0` 版本以前且开启缓存情况下，会先查询缓存，以这条 `sql` 语句为 `key的哈希值` 在内存中查询是否有结果，如果有直接缓存，如果没有，执行下一步。

- 通过 `解析器和预处理器` 进行词法分析，提取 `sql` 语句的关键元素，比如提取语句是查询 `select`，提取需要查询的 `表名` 为，需要查询所有的列，查询条件等。然后判断这个 `sql` 语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就生成 `解析树`。生成解析树之后还会对其进行验证，比如验证字段，表等是否存在，解析名字和别名是否有歧义等

- 接下来就是优化器进行确定执行方案，优化器根据自己的优化算法进行选择执行效率最好的一个方案（优化器认为，有时候不一定最好）。并生成执行计划后就准备开始执行了

- 执行器简单的根据执行计划的指令逐步执行。开始执行的时候，会先判断这个表是否有权限，如果没有就直接返回权限错误，如果有权限就会调用数据库引擎接口，返回引擎的执行结果

##### 更新语句

更新语句前面的步骤和查询一致，解析器通过解析知道这是一条更新语句，然后执行器选择最优执行计划去执行

- 执行器会先 `open table`，如果该表上有 `MDL（X）`（元数据排他锁），则等待。如果没有则在该表上加 MDL（S）（元数据共享锁） `-----> 服务层`

- 进入到引擎层，首先会去缓存里里的 `data dictionary` (元数据信息，是InnoDB自己管理的表缓存) 得到表信息，通过元数据信息，去 `lock info` 里查出是否会有相关的锁信息，并把这条update语句需要的锁信息写入到 `lock info` 里

- 然后涉及的旧数据以快照的形式存储到缓冲池中的 `undo page` 里，并在 `redo log` 中记录 `undo log`（undo log持久化）

- 然后对数据页进行修改，并把数据页的物理修改记录到 `redo log buffer（缓存）`里，同时将这个更新操作记录到 `redo log` 里面，此时 `redo log` 处于 `prepare` 状态，然后返回执行器可以提交了

还需要在二级索引上做的修改，写入到 `change buffer page`，等到下次有读取该二级索引页时，再去与二级索引页做 `merge`

- 执行器收到通知后记录 `binlog_cache`，同时修改的信息会按照 `event` 的格式，以不同的 `event type` 记录到 `binlog_cache` 中，在事务 `commit` 后 `dump` 线程会从 `binlog_cache` 里把 `event` 发送给 `slave` 的 `I/O` 线程

- 执行器调用引擎的提交事务接口，引擎把刚刚写入的 `redo log` 改成提交（commit）状态，更新完成


#### MyISAM和InnoDB的区别

- **对锁的支持**

`MyISAM` 只有表级锁(table-level locking)，而 `InnoDB` 支持行级锁(row-level locking)和表级锁，默认为行级锁

- **是否支持事务**

`MyISAM` 不提供事务支持。

`InnoDB` 提供事务支持，具有提交(commit)和回滚(rollback)事务的能力

- **是否支持外键**

`MyISAM` 不支持，而 `InnoDB` 支持


- **是否支持数据库异常崩溃后的安全恢复**

`MyISAM` 不支持，而 `InnoDB` 支持

使用 `InnoDB` 的数据库在异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态。这个恢复的过程依赖于 `redo log`


- **是否支持 MVCC**

`MyISAM` 不支持，而 `InnoDB` 支持


>MySQL InnoDB 引擎使用 **redo log(重做日志)** 保证事务的持久性，使用 **undo log(回滚日志)** 来保证事务的原子性
>
>MySQL InnoDB 引擎通过 **锁机制**、**MVCC** 等手段来保证事务的隔离性（ 默认支持的隔离级别是 `REPEATABLE-READ` ）。
>
>保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。


#### 自增值保存在哪里？用完了怎么办？


- `MyISAM` 引擎的自增值保存在数据文件中

- `InnoDB` 引擎的自增值到了 `MySQL 8.0` 版本后，才有了“自增值持久化”的能力，具体情况是：

  - 在 `MySQL 5.7` 及之前的版本，自增值保存在内存里，并没有持久化。每次重启后，第一次打开表的时候，都会去找自增值的最大值 max(id)，然后将 max(id)+1 作为这个表当前的自增值。﻿举例来说，如果一个表当前数据行里最大的 id 是 10，AUTO_INCREMENT=11。这时候，我们删除 id=10 的行，AUTO_INCREMENT 还是 11。但如果马上重启实例，重启后这个表的 AUTO_INCREMENT 就会变成 10。﻿也就是说，MySQL 重启可能会修改一个表的 AUTO_INCREMENT 的值。
  
  - 在 `MySQL 8.0` 版本，将自增值的变更记录在了 `redo log` 中，重启的时候依靠 `redo log` 恢复重启之前的值
  


**表定义的自增值达到上限后的逻辑是：再申请下一个 id 时，得到的值保持不变**，如果是主键在插入的时候就会报错了。

#### 怎么给线上的大表添加索引？

#### 说说Double-Write（解决什么问题，工作流程）

#### RR级别下会产生幻读吗？InnoDB是怎么解决的？

不会。在 `InnoDB` 存储引擎中，通过使用 `Next-key Lock` 算法来避免幻读的问题。在 `Next-Key Lock` 算法下，对于索引的扫描，不仅是锁住扫描到的索引，而且还锁住这些索引覆盖的范围(gap)。因此在这个范围内的插人都是不允许的。这样就避免了另外的事务在
这个范围内插人数据导致的幻读的问题。**因此, INNODB存储引聱的默认事务隔离级别是 `READ REPEATABLE` ，采用 `Next-key Lock` 算法,避免了幻读的现象**

**为什么RC级别下会产生幻读？**

因为在RC级别下仅使用了 `Record Lock` ，所以会导致

#### 什么是不可重复读？RR级别下是如何避免的？


#### 你是怎么优化数据库的？

- 1、选择最合适的字段属性：类型、⻓度、是否允许NULL等；尽量把字段设为not null，⼀⾯查询时对⽐是否为null；
- 2.要尽量避免全表扫描，⾸先应考虑在 where 及 order by 涉及的列上建⽴索引。
- 3.应尽量避免在 where ⼦句中对字段进⾏ null 值判断、使⽤!= 或 <> 操作符，否则将导致引擎放弃使⽤索引⽽进⾏全表扫描
- 4.应尽量避免在 where ⼦句中使⽤ or 来连接条件，如果⼀个字段有索引，⼀个字段没有索引，将导致引擎放弃使⽤索引⽽进⾏全
表扫描
- 5.in 和 not in 也要慎⽤，否则会导致全表扫描
- 6.模糊查询也将导致全表扫描，若要提⾼效率，可以考虑字段建⽴前置索引或⽤全⽂检索；
- 7.如果在 where ⼦句中使⽤参数，也会导致全表扫描。因为SQL只有在运⾏时才会解析局部变量，但优化程序不能将访问计划的选择
推迟到运⾏时；它必须在编译时进⾏选择。然 ⽽，如果在编译时建⽴访问计划，变量的值还是未知的，因⽽⽆法作为索引选择的输⼊项。
- 9.应尽量避免在where⼦句中对字段进⾏函数操作，这将导致引擎放弃使⽤索引⽽进⾏全表扫描。
- 10.不要在 where ⼦句中的“=”左边进⾏函数、算术运算或其他表达式运算，否则系统将可能⽆法正确使⽤索引。
- 11.在使⽤索引字段作为条件时，如果该索引是复合索引，那么必须使⽤到该索引中的第⼀个字段作为条件时才能保证系统使⽤该索
引，否则该索引将不会被使⽤，并且应尽可能的让字段顺序与索引顺序相⼀致。
- 12.不要写⼀些没有意义的查询，如需要⽣成⼀个空表结构：
- 13.Update 语句，如果只更改1、2个字段，不要Update全部字段，否则频繁调⽤会引起明显的性能消耗，同时带来⼤量⽇志。
- 14.对于多张⼤数据量（这⾥⼏百条就算⼤了）的表JOIN，要先分⻚再JOIN，否则逻辑读会很⾼，性能很差。
- 15.select count(*) from table；这样不带任何条件的count会引起全表扫描，并且没有任何业务意义，是⼀定要杜绝的。
- 16.索引并不是越多越好，索引固然可以提⾼相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert
或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况⽽定。⼀个表的索引数最好不要超过6个，若太多则应考虑⼀些不常使
⽤到的列上建的索引是否有 必要。
- 17.应尽可能的避免更新 clustered 索引数据列，因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，⼀旦该列值改
变将导致整个表记录的顺序的调整，会耗费相当⼤的资源。若应⽤系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为
clustered 索引。
- 18.尽量使⽤数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为
引擎在处理查询和连 接时会逐个⽐较字符串中每⼀个字符，⽽对于数字型⽽⾔只需要⽐较⼀次就够了。
- 19.尽可能的使⽤ varchar/nvarchar 代替 char/nchar ，因为⾸先变⻓字段存储空间⼩，可以节省存储空间，其次对于查询来
说，在⼀个相对较⼩的字段内搜索效率显然要⾼些。
- 20.任何地⽅都不要使⽤ select * from t ，⽤具体的字段列表代替“*”，不要返回⽤不到的任何字段。
- 21.尽量使⽤表变量来代替临时表。如果表变量包含⼤量数据，请注意索引⾮常有限（只有主键索引）。
- 22. 避免频繁创建和删除临时表，以减少系统表资源的消耗。临时表并不是不可使⽤，适当地使⽤它们可以使某些例程更有效，例如，
当需要重复引⽤⼤型表或常⽤表中的某个数据集时。但是，对于⼀次性事件， 最好使⽤导出表。
- 23.在新建临时表时，如果⼀次性插⼊数据量很⼤，那么可以使⽤ select into 代替 create table，避免造成⼤量 log ，以提
⾼速度；如果数据量不⼤，为了缓和系统表的资源，应先create table，然后insert。
- 24.如果使⽤到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可
以避免系统表的较⻓时间锁定。
- 25.尽量避免使⽤游标，因为游标的效率较差，如果游标操作的数据超过1万⾏，那么就应该考虑改写。
- 26.使⽤基于游标的⽅法或临时表⽅法之前，应先寻找基于集的解决⽅案来解决问题，基于集的⽅法通常更有效。
- 27.与临时表⼀样，游标并不是不可使⽤。对⼩型数据集使⽤ FAST_FORWARD 游标通常要优于其他逐⾏处理⽅法，尤其是在必须引⽤
⼏个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要⽐使⽤游标执⾏的速度快。如果开发时 间允许，基于游标的⽅法和基于集的⽅法
都可以尝试⼀下，看哪⼀种⽅法的效果更好。
- 28.在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON ，在结束时设置 SET NOCOUNT OFF 。⽆需在执⾏存储过程和触
发器的每个语句后向客户端发送 DONE_IN_PROC 消息。
- 29.尽量避免⼤事务操作，提⾼系统并发能⼒。
- 30.尽量避免向客户端返回⼤数据量，若数据量过⼤，应该考虑相应需求是否合理